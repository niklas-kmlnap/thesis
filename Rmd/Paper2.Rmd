---
title:        "Paper 2: survey analysis"
author:       "Niklas Karlsen"
date:         "2024-09-05"
bibliography: "../data/meta_data/references.bib"
csl:          "../scripts/university-of-gothenburg-apa-7th-edition-swedish-legislations.csl" # (source: https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html)
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), '../output/paper2.html')) })
---

# Introduction

This document presents the quantitative analyses done in paper 2. Descriptive and inferential analyses are done. The inferences are based on multiple regression analyses. The document is inspired by the idea of a computational essay [@odden_using_2023].

The purpose is foremost to reproduce the results presented in paper 2. But I will also do a reanalysis excluding some interaction effects, which were included in the paper 2 analysis. In addition, I will compare the multiple regression analysis with multilevel modeling, to see if the results are similar, as well as when including cross-level interaction effects due to year of study (semester), since there could be differences in different years either due to changes in the student population or at the teacher education institutes. 

## Load libraries

```{r load_libraries}

### prepare raw data
library(readxl)                             # read .xlsx-files. Kilde: https://readxl.tidyverse.org/

### presentation of results
library(pander)                             # prettyprint for tables

# NB! Collision between plyr and dplyr!
library(plyr)
library(dplyr)                              # rename columns
#library(tidyr)

library(ggplot2)
library(viridis)

### analyses
library(mice)                               # for md.pattern (missing)
library(psych)                              # for ICC, SD

# cluster-variable
# kilde: https://www.r-bloggers.com/2021/05/clustered-standard-errors-with-r/
library(estimatr)                           # for cluster corrected SE
#library(sandwich)
#library(lmtest)
library(nlme)                               # for ICC - variance HLM
```



## Define constructs 

The constructs are based on @karlsen_assessing_2024.

```{r load_constructs}
## TPACK-PST for TRELIS-Q
TK_pos_trelisq    <- c("TK1b","TK2","TK34") 
PCK_pos_trelisq   <- c("CK123","CK5","PCK2","PCK5")
TPACK_pos_trelisq <- c("TPACK2","TPACK4","TCK1","TCK4","TPK1","TPK4") 

TPACK_trelis_q    <- list(TK=TK_pos_trelisq,
                     PCK=PCK_pos_trelisq,
                     TPACK=TPACK_pos_trelisq)
```

# Method

The following approach is used in this document. First, the raw data is loaded and prepared for analyses. Second, descriptive statistics are created. Third, inferential statistics (i.e., regression analyses) are created. Finally, some comments are provided on the results.

Since the data is structured at two levels (i.e., PSTs and TEIs), the data is not independent as is assumed when doing OLS regression. Since only 5 TEIs are in the dataset, which is below the recommended miminum of 10, OLS with cluster corrected standard errors may be a feasible option to MLM. 

The ICC is checked to see how much of the variance is accounted for by the level 2 units, to assess whether it is necessary to account for the level 2-dependence. ICC should be above 5 % for MLM to be considered. 

The OLS regression is hierarchical. The covariates are introduced block-wise. Gender and target grade is related to the individual PST, while year of study can reflect both changes at level 1 and level 2. 

For the OLS the TEIs are introduced as dummy variables, as are the other covariates with more than two levels. 

For the multi-level modeling (MLM) the PSTs are considered level 1 units and the TEIs are level 2. The covariates gender and target grade are related to the level 1 units, while year of study can vary at both levels. 

In addition, TK and PCK are considered independent variables, while TPACK is the dependent variable. 

Both the OLS and the MLM are done by introducing the variables sequentially. For the OLS done in paper 2, the level 1 variables (i.e., gender, trinn and semester) are introduced first, then the level 2 variables (i.e., TEIs), and finally, PCK and TK. For the MLM, a baseline model (null-model) is created first, where the TEIs are set as random (i.e., the intercept is allowed to vary among TEIs). Then the level 1 variables are introduced to create the level 1-model. Then PCK and TK are added to the model. Since the order of introducing TEI was altered between the OLS in paper 2 and the MLM, a reanalysis of the OLS was done with the TEIs introduced before the covariates. This could affect how much of the variance was explained by the covariates.

The explained variance (i.e., R2) is calculated for both methods, and can be used to compare the results of the two methods. 

The following models are tested:

Model | Paper 2 OLS | Reanalysis OLS | New analysis MLM 
------------- | ------------- | ------------- | ------------- 
Options | 3xAnnet = NA | N/A | N/A
Nullmodell | N/A | TPACK ~ TEIs | TPACK ~ 1
Level 1 | TPACK ~ covariates + TEIs | TPACK ~ TEIs + covariates | TPACK ~ covariates
Level 2 | N/A | N/A | + year of study | TEI
PCK | TPACK ~ covariates + TEIs + PCK | TPACK ~ TEIs + covariates + PCK | TPACK ~ covariates + PCK_sentrert
TK | TPACK ~ covariates + TEIs + PCK + TK | TPACK ~ TEIs + covariates + PCK + TK | TPACK ~ covariates + PCK_s + TK_sentrert

The analysis in paper 2 changed the answers of three respondents from "Other" to NA. This made it impossible to compare the fit for the MLMs since the number of respondents were dissimilar for the models compared when including these covariates. For the reanalyses I therefore kept these values unchanged. 

In the MLM the TEIs are added as random variables (i.e., the intercepts are allowed to differ between TEIs), while the TEIs are added as dummy variables in the OLS. This should give similar results. 

In the MLM the covariates are added as fixed variables (i.e., the slopes are the same for all PSTs independent of TEI). 

The order of the models was also changed in the reanalysis, as the baseline model in the MLM corresponds to having the TEIs as dummy variables. In paper 2 this model was tested after having controlled for the covariates. In the reanalysis this order was switched to correspond to the MLM.

Only the MLM has the option to test for level 2 covariates. I allowed slope of year of study vary between TEIs. The level2 model is therefore not tested. It did not converge.

For the MLM the independendent variables were centred using the grand mean, following @christophersen_introduksjon_2018.

The different methods can be compared by comparing R-squared, and diff R-squared. 

## Data management

For the survey, the complete TRELIS-Q dataset was used. Here I load the raw data and prepare it for analysis. 

### Load data

```{r}
folder_trelis_q <- "../data/rawdata/"
trelis_q <- "trelis-q-datafil-endelig-juni2023.xlsx"

path_trelis_q <- paste(folder_trelis_q, trelis_q, sep='')

data_trelis_q <- read_excel(path_trelis_q, sheet=4)
```

### Data cleaning

```{r}
# only keep relevant columns
data_trelis_q <- data_trelis_q[,51:74]
```

```{r}
# keep some columns; covariates
# 68. Hvilket studiested studerer du ved?	
# 69. Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?	
# 70. Hvilket studieår er du i?	
# 71. Er du:

# likert-spørsmål: 48 - 66
# åpne spørsmål: 67

data_trelis_q <- rename(data_trelis_q,
                            "Trinn" =
                            "69. Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?")
data_trelis_q <- rename(data_trelis_q,
                            "Gender" =
                            "71. Er du:")
data_trelis_q <- rename(data_trelis_q,
                            "studiested" =
                            "68. Hvilket studiested studerer du ved?")
data_trelis_q <- rename(data_trelis_q,
                            "semester" =
                            "70. Hvilket studieår er du i?")

# change from year to semester
#data_trelis_q$semester <- rep(7, 52)  # 4 år =  7. semester (høst)

# reorder some columns
data_trelis_q <- data_trelis_q %>% relocate(Trinn, .before = "48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_trelis_q <- data_trelis_q %>% relocate(Gender, .before = "48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_trelis_q <- data_trelis_q %>% relocate(studiested, .before = "Trinn")
data_trelis_q <- data_trelis_q %>% relocate(semester, .before = "Trinn")
```

Rename items to TPACK-lingo. (introduce bias in interpretation? Should it be named something neutral instead?)

```{r}
# rename columns: (bruker dplyr)
# kilde: https://www.sharpsightlabs.com/blog/rename-columns-in-r/
data_trelis_q_ren <- rename(data_trelis_q, 
'CK123' = '48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.',
'CK4' = "49. Jeg forstår teknologiske prinsipper og virkemåter som er relevante for naturfag",
'CK5' = '50. Jeg har kunnskaper om naturvitenskapelige praksiser og tenkemåter',
'PCK2' = '51. Jeg vet hvordan jeg kan støtte elevene i å utvikle kritisk tenkning og argumentasjonsferdigheter i naturfag',
'TK2' = "52. Jeg kan sette opp en algoritme når jeg programmerer",
'TK1a' = "53. Jeg kan bryte ned problemer i mindre deler når jeg programmerer",
'TK34' = "54. Jeg har kunnskap om forskjellige programmeringsverktøy, f.eks. Makecode for Micro:bit, Scratch, Python, og lignende",
'TK1b' = "55. Jeg kan oppdage og rette feil, når jeg programmerer.",
'TK567' = "56. Jeg vet hvordan jeg lager kode som inneholder f.eks. variabler, vilkår (if, else) og løkker (for, while)",
'TCK1' = "58. Jeg kan bruke programmering til å utvikle enkle teknologiske systemer som består av deler som virker sammen.",
'TCK4' = '57. Jeg kan bruke programmering til å utforske naturfaglige fenomener',
'PK3' = '59. Jeg kan støtte elevene sosialt i deres læring i ulike fag, f.eks deres nysgjerrighet, kreativitet og samarbeidsevne',
'PK1' = '60. Jeg vet hvordan jeg kan støtte elevenes refleksjon over egen læring i ulike fag',
'PCK5' = '61. Jeg vet hvordan jeg kan vurdere elevenes læring på ulike måter i naturfag',
'TPK1' = '62. Jeg vet hvordan jeg kan bruke programmering på måter som beriker undervisningen i ulike fag',
'TPK4' = '63. Jeg tenker kritisk igjennom hvordan jeg kan bruke programmering i undervisningen i ulike fag',
'TPACK2' = '64. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå naturfaglige begreper og fenomener',
'TPACK3' = '65. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå naturvitenskapelige praksiser og tenkemåter.',
'TPACK4' = '66. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå hvordan teknologiske systemer fungerer')

# change "5 Stemmer veldig godt" and "1 Stemmer veldig dårlig" to 5 and 1
data_trelis_q_ren[data_trelis_q_ren == '1 Stemmer veldig dårlig'] <- "1"
data_trelis_q_ren[data_trelis_q_ren == '5 Stemmer veldig godt'] <- "5"
```

```{r}
# hva gjør jeg med 9 / VET IKKE? Gjør om til NA?
# tell antall VET IKKE
antall_VETIKKE <- length(which(data_trelis_q_ren == 'VET IKKE'))
print(antall_VETIKKE)
# gjør om til NA; OBS! Ikke gjør disse NA om til tall med impute, pmm senere
data_trelis_q_ren[data_trelis_q_ren == 'VET IKKE'] <- NA # "9"

# convert into numbers
data_trelis_q_ren[,colnames(data_trelis_q_ren) %in% unlist(TPACK_trelis_q)] <-
  apply(
    data_trelis_q_ren[,colnames(data_trelis_q_ren) %in% unlist(TPACK_trelis_q)], 2,
                    function(x) as.numeric(as.character(x)))
```

Hvor mange respondenter er det?

```{r}
nrow(data_trelis_q)
nrow(data_trelis_q_ren)
```

```{r rename_dataset}
data_TRELIS_Q <- data_trelis_q_ren
```

```{r}
# remove open-ended question column
data_TRELIS_Q <- data_TRELIS_Q[,1:23]
```

```{r}
# readxls stores as tibble, not dataframe?
# make tibble into data.frame to treat it similarly to pilot dataset
data_TRELIS_Q <- data.frame(data_TRELIS_Q)
```

### save data

```{r}
save(data_TRELIS_Q,  
     file="../data/processed_data/tpack-TRELIS-Q_complete_2023-paper2.Rdata")
```

```{r}
# clean environment to reset for next step
# ref.: https://www.statology.org/clear-environment-in-r/ [3.9.2024]
rm(list=ls())
```

## Prepare data

The environment is reset and the data reloaded. 

```{r load_data}
# Rdata-file contains reduced / prepared datasets
load(file="../data/processed_data/tpack-TRELIS-Q_complete_2023-paper2.Rdata")
```

```{r reload_constructs}
## TPACK-PST for TRELIS-Q
TK_pos_trelisq    <- c("TK1b","TK2","TK34") 
PCK_pos_trelisq   <- c("CK123","CK5","PCK2","PCK5")
TPACK_pos_trelisq <- c("TPACK2","TPACK4","TCK1","TCK4","TPK1","TPK4") 

TPACK_trelis_q    <- list(TK=TK_pos_trelisq,
                     PCK=PCK_pos_trelisq,
                     TPACK=TPACK_pos_trelisq)
```

## Help functions

```{r}
# describe data (mean, sd, skew, curtosis)
describe_data <- function (datalist, QUIET=1) {
  im <- mean(datalist, na.rm=TRUE)
  isd <- sd(datalist, na.rm=TRUE)
  isk <- psych::skew(datalist, na.rm=TRUE) # from psych
  ik <- kurtosi(datalist, na.rm=TRUE) # from psych
  mis <- sum(is.na(datalist)) # missing
  ir <- max(datalist, na.rm=TRUE) -          
    min(datalist, na.rm=TRUE) # range
  
  # source: https://stackoverflow.com/questions/34351598/getting-name-of-variable-in-r
  if (QUIET != 1) {
    print(sprintf("%7s = %s", "Item", deparse(substitute(datalist))))
    print(sprintf("%7s = %.3f", "mean", im))
    print(sprintf("%7s = %.3f", "std.dev", isd))
    print(sprintf("%7s = %.3f", "skew", isk))
    print(sprintf("%7s = %.3f", "kurt", ik))
    print(sprintf("%7s = %.3f", "range", ir))
    print(sprintf("%7s = %i", "missing", mis))

    if (isk > 2 | ik > 7) {
      print("                            Skew or curtosis TOO LARGE.")
    }
  }
  
  # outliers
  lowerq = quantile(datalist, na.rm=TRUE)[2]
  upperq = quantile(datalist, na.rm=TRUE)[4]
  iqr = upperq - lowerq #Or use IQR(df)
  # gang med 3 for extreme outliers, 1.5 for mild outliers
  
  mild.threshold.upper = (iqr * 3) + upperq
  mild.threshold.lower = lowerq - (iqr * 3)
  
  # print outliers
  # kilde: https://stackoverflow.com/questions/19353116/how-do-i-print-values-in-a-list-that-are-greater-than-a-certain-number-along-wit#19353192
  outliers_upper <- which(datalist>mild.threshold.upper)
  outliersu <- datalist[outliers_upper]
  outliers_lower <- which(datalist<mild.threshold.lower)
  outliersl <- datalist[outliers_lower]
  
  if (length(outliersu) > 0 | length(outliersl) > 0) {
    print("outliers upper =")
    print(outliersu)
    print("outliers lower =")
    print(outliersl)
  }
  
  #hist (datalist, main=i) # histogram
  #readline(prompt = "Press enter")
  
  return(c("mean"=round(im,3), "skew"=round(isk,3), "kurtosi"=round(ik,3)))
           #round(outliersu,3), round(outliersl,3)))
}

###
# helper functions from http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/
###

## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  #library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column  ; from plyr package
  datac <- plyr::rename(datac, c("mean" = measurevar))
  #datac <- rename(datac, measurevar = "mean") # oppdatert til ny versjon av dplyr
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}

## Norms the data within specified grupper in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
  #library(plyr)
  
  # Measure var on left, idvar + between vars on right of formula.
  data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                         .fun = function(xx, col, na.rm) {
                           c(subjMean = mean(xx[,col], na.rm=na.rm))
                         },
                         measurevar,
                         na.rm
  )
  
  # Put the subject means with original data
  data <- merge(data, data.subjMean)
  
  # Get the normalized data in a new column
  measureNormedVar <- paste(measurevar, "_norm", sep="")
  data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
    mean(data[,measurevar], na.rm=na.rm)
  
  # Remove this subject mean column
  data$subjMean <- NULL
  
  return(data)
}

```

Flytt origo

```{r}
data_TRELIS_Q[,unlist(TPACK_trelis_q)] <- data_TRELIS_Q[,unlist(TPACK_trelis_q)] - 3 
```

```{r}
# identify NA as studiested 5(?) 
data_TRELIS_Q[data_TRELIS_Q$studiested == "Institute3","Trinn"] <- "Trinn 5-10"
```

## Check for missing

The complete TRELIS_Q dataset is almost identical to the trelis_q dataset used in paper 1, except that TRELIS_Q includes all answers from institute2. These were not all collected when paper 1 was written. The addition of these final answers did not add any new NMAR to the dataset. 

```{r}
# covariates
md.pattern(data_TRELIS_Q[,c("studiested","Gender", "Trinn", "semester")])

# items / likert data
md.pattern(data_TRELIS_Q[, unlist(TPACK_trelis_q)])
```

```{r fix_missing, eval=T}
# remove NMAR + Institute9 (19)
data_clean <- data_TRELIS_Q[-c(19,34,44,45,46,95,102),] 
```

To reproduce paper 2 values, I set the answers "Other" to NA.

```{r}
# jeg skjuler Annet, siden det bare er en person; alternativt NA?
data_clean$Trinn[data_clean$Trinn == "Annet"] <- NA # "Trinn 5-10"
#trinn_r[is.na(trinn_r)] <- 1
  
# jeg skulet Annet / ønsker ikke å oppgi, siden det bare er to personer
# skjuler som Kvinne, siden det er flest av de
data_clean$Gender[data_clean$Gender == "Annet/ønsker ikke å oppgi"] <- NA # "Kvinne"
#gender_r[is.na(gender_r)] <- 1

# merge 2. and 3. year (Naturfag 1)
#data_clean$semester[data_clean$semester == "2. år"] <- "3. år"
```

# Descriptive statistics

Covariates:

* target grade level (Trinn): level 1-7 or level 5-10
* institute: 5 institutes
* gender: male or female
* year of study (semester): 2., 3. or 5. year

```{r}
scores_v23 <- scoreItems(TPACK_trelis_q, data_clean)

describe(scores_v23$scores)

# constructs for multiple regression
TK_v23    <- scores_v23$scores[,"TK"]
PCK_v23   <- scores_v23$scores[,"PCK"]
TPACK_v23 <- scores_v23$scores[,"TPACK"]

# add constructs to data.frame
data_clean$TK    <- TK_v23
data_clean$PCK   <- PCK_v23
data_clean$TPACK <- TPACK_v23
```

## Bargraphs: comparing institutes

```{r}
# group institutes into three: low, medium, high
data_clean$studiested2 <- factor(data_clean$studiested, 
                                 level=c("Institute1","Institute5","Institute3","Institute2","Institute4"),
                                 label=c("A", "A", "B", "C", "C"))

dc1 <- summarySE(data_clean, measurevar="TK", groupvars="studiested2")
dc2 <- summarySE(data_clean, measurevar="PCK", groupvars="studiested2")
dc3 <- summarySE(data_clean, measurevar="TPACK", groupvars="studiested2")

# rename; kilde: https://www.statology.org/rename-single-column-in-r/
colnames(dc1)[colnames(dc1) == "TK"] <- "var"
colnames(dc2)[colnames(dc2) == "PCK"] <- "var"
colnames(dc3)[colnames(dc3) == "TPACK"] <- "var"

# merge data
dc <- rbind(dc1,dc2)
dc <- rbind(dc,dc3)

# add column med navn
dc["TPACK"] <- c("TK","TK","TK","PCK","PCK","PCK","TPACK","TPACK","TPACK")
```

```{r}
stolpediagram <- ggplot(dc, aes(x=studiested2, y=var, fill=studiested2)) + 
  geom_bar(stat="identity", position="dodge") +
  #scale_fill_manual(values=viridis(3)) + 
  geom_errorbar(aes(ymin=var-sd, ymax=var+sd), # se
                  linewidth=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9)) +
  ggtitle("PCK, TK og TPACK fordelt på studiested") +
  guides(fill="none") +
  # https://stackoverflow.com/questions/53843221/make-y-axis-start-at-1-instead-of-0-within-ggplot-bar-chart
#  coord_cartesian(ylim = c(1,5)) +
  ylab("verdi") +
  xlab("studiested gruppe") +
  theme_bw() +
  facet_wrap(~TPACK)

print(stolpediagram) # vis plot
```

# Multiple regression analysis

The purpose of the multiple regression analysis is to explain the variation in the data. I therefore use hierarchical regression [@howitt_introduction_2014] and add the variables step-by-step to examine changes in R2 (explained variance). 

## Check assumptions for regression

The data is however multilevel, as the PSTs (level 1) are grouped at the institutional level (level 2). I therefore also have to test whether I need to use hierarchical level modeling (HLM) by examining the intraclass correlation coefficient (ICC) of the data. 

ICC is calculated to check whether HLM must be done. 

Multiple regression assumes independent observations and linearity between dependent and independent variables. In addition, the residuals should be normally distributed, to calculate test statistics for doing inferences. 

### ICC

To check whether to treat the data as multilevel, ICC is calculated [@christophersen_introduksjon_2018] (p. 109-111).

```{r ICC}
# variance decomposition
null.mod <- lme(TPACK ~ 1, random =~ 1|studiested, data = data_clean)
vcn <- VarCorr(null.mod)
vcn
```

The variance of indviduals is given by the residual. The variance of institutions is givene by the intercept. If the variance of the intercept is larger than 0.05 of the total variance (intercept + residual), then the institutional variance contributes to explain the outcome.  

The ICC indicates that the data are nested. But since there is only 5 institutes, I used cluster corrected standard errors, instead of HLM, as suggested by @christophersen_introduksjon_2018.

lm_robust [@blair_estimatr_2022] is used to calculate cluster corrected standard errors. (or robust SE? Actually, CR2 SE = cluster robust standard errors)

### Normality

The residuals need to be normally distributed for the statistical tests. For dichotomous variables, the distribution should be less than 80/20 skewed. 

```{r normality}
# covariates; 80/20 distribution
# ref http://stackoverflow.com/questions/21639392/ddg#21639445
barplot(prop.table(table(data_clean$Gender)))
barplot(prop.table(table(data_clean$Trinn)))
barplot(prop.table(table(data_clean$semester)))
#hist(Institute4_r)
#hist(Institute2_r)
#hist(Institute1_r)
#hist(Institute5_r)

# variable
hist(data_clean$TK)
hist(data_clean$PCK)
hist(data_clean$TPACK)
```

```{r}
describe_data(data_clean$TK)
describe_data(data_clean$PCK)
describe_data(data_clean$TPACK)
```

### Linearity

The data should be linearly related. 

```{r scatterplot_linearity}
# ref: https://stackoverflow.com/questions/29425892/how-do-i-loop-through-column-names-and-make-a-ggplot-scatteplot-for-each-one
for (var1 in names(data_clean)[names(data_clean) %in% c("Gender", "Trinn", "semester", "TK", "PCK")]) {
  xy_plot <- ggplot(data_clean, aes(.data[[var1]],TPACK)) +
        geom_point() +                            # shape=1,alpha=1/5
        geom_jitter() +
        ggtitle(paste("scatterplot",var1,"TPACK"))

  print(xy_plot)
}

#plot(data_clean$Trinn,         data_clean$TPACK)
#plot(data_clean$semester,      data_clean$TPACK)
#plot(data_clean$TK,            data_clean$TPACK)
#plot(data_clean$PCK,           data_clean$TPACK)
```

```{r multicollinearity}
#cor(data_clean$PCK,   data_clean$semester)
#cor(data_clean$TPACK, data_clean$Gender)

#cor(data_clean$TK,    data_clean$Gender)
#cor(data_clean$TK,    data_clean$Trinn)

cor(data_clean$TK,    data_clean$PCK)
cor(data_clean$TK,    data_clean$TPACK)
cor(data_clean$PCK,   data_clean$TPACK)
```

TK korrelererer veldig sterkt (0.84) med TPACK, noe som indikerer kollinearitet (Jeong and Jung, 2016). This issue is discussed in @karlsen_assessing_2024 and the synopsis. 

## Check for interactions

Should I include interactions in the regression analysis? Interaction plots are drawn to see for effects of interaction. Any crossing lines indicate interaction effects. Parallel lines indicate no interaction. 

### TK Level 1

```{r TK_gender_trinn}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$Trinn),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Target grade level")
```

Different signs on slope, a clear indication of interaction effects on TK from gender and target grade level.

```{r TK_gender_semester}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Year of study")
```

```{r TK_semester_trinn}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Trinn),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Target grade level",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Year of study")
```

### TK Level 2

```{r TK_semester_institute}
interaction.plot(x.factor = factor(data_clean$semester), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Year of study",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

A clear interaction effect between institute and semester on TPACK.

```{r TK_trinn_institute}
interaction.plot(x.factor = factor(data_clean$Trinn), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Target grade level",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

```{r TK_gender_institute}
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$studiested), #label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TK,
                 type = "b",
                 ylab = "TK",
                 xlab = "Gender",
                 col = viridis(5), #c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

### PCK Level 1

```{r PCK_gender_trinn}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$Trinn),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Target grade level")
```

Different signs on slope, a clear indication of interaction effects on PCK from gender and target grade level.

```{r PCK_gender_semester}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Year of study")
```

```{r PCK_semester_trinn}
# ref https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Trinn),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Target grade level",
                 col = viridis(2), # c("pink", "blue"), 
                 trace.label = "Year of study")
```

### PCK Level 2

```{r PCK_semester_institute}
interaction.plot(x.factor = factor(data_clean$semester), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Year of study",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

A clear interaction effect between institute and semester on TPACK.

```{r PCK_trinn_institute}
interaction.plot(x.factor = factor(data_clean$Trinn), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Target grade level",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

```{r PCK_gender_institute}
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$studiested), #label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$PCK,
                 type = "b",
                 ylab = "PCK",
                 xlab = "Gender",
                 col = viridis(5), #c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

### TPACK Level 1

```{r TPACK_gender_trinn}
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$Trinn),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"),
                 trace.label = "Target grade level")
```

Not so clear interaction effect, similar slopes? They do cross eventually. 

```{r TPACK_gender_semester}
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Gender",
                 col = viridis(2), # c("pink", "blue"),
                 trace.label = "Study year")
```

```{r TPACK_trinn_semester}
# https://www.statology.org/interaction-plot-r/
interaction.plot(x.factor = factor(data_clean$Trinn),
                 trace.factor = factor(data_clean$semester),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Target grade level",
                 col = viridis(2), # c("pink", "blue"),
                 trace.label = "Study year")
```

### TPACK Level 2

```{r TPACK_semester_institute}
interaction.plot(x.factor = factor(data_clean$semester), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Year of study",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

A clear interaction effect between institute and semester on TPACK.

```{r TPACK_trinn_institute}
interaction.plot(x.factor = factor(data_clean$Trinn), # label=c("Year 2/3", "Year 5")),
                 trace.factor = factor(data_clean$studiested), # label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Target grade level",
                 col = viridis(5), # c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

```{r TPACK_gender_institute}
interaction.plot(x.factor = factor(data_clean$Gender),
                 trace.factor = factor(data_clean$studiested), #label=c("institute 1", "institute 2", "institute 3", "institute 4", "institute 5")),
                 response = data_clean$TPACK,
                 type = "b",
                 ylab = "TPACK",
                 xlab = "Gender",
                 col = viridis(5), #c("red", "green", "orange", "pink", "blue"),
                 trace.label = "Institute")
```

Not so clear interaction on TPACK from gender and institute.

### Summary of interaction effects

TK level 1 (PST):

* possible interaction between gender and target grade level (Trinn)
* possible interaction between gender and year of study (semester)

TK level 2 (TEI):

* possible interaction between institute and year of study (semester)
* possible weak interaction between institute and target grade level (Trinn)
* possible interaction between gender and institute

PCK level 1:

* possible weak interaction between gender and target grade level
* possible interaction between gender and year of study (semester)
* possible weak interaction between target grade level and year of study

PCK level 2:

* possible interaction between institute and year of study
* possible weak interaction between institute and target grade level 
* possible interaction between institute and gender

TPACK level 1:

* possible interaction between gender and year of study

TPACK level 2:

* possible interaction between institute and year of study
* possible weak interaction between institute and gender

The significance of these interaction effects have to be tested for when doing the regression analysis.

## Replication of paper 2 results

Here I reproduce the results reported in paper 2. Interaction effects were also tested to see if they needed to be included in the analysis. 

### Hierarchical RA for TK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

Interaction effects are examined by calculating F-statistics to see if models with and without interaction are significantly different. 

#### Level 1

First, all covariates at the individual PST level 1 (i.e., gender, target grade level and year of study) are introduced as a block. 

Without interaction

```{r TKlevel1_main_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_TK_covariates_l1 <- lm_robust(TK ~ factor(Gender) + (factor(Trinn) + factor(semester)), 
                clusters = factor(studiested), data=data_clean)
summary(model_TK_covariates_l1)
```

With interaction

when calculating interaction effects, TK needs to be standardized [@christophersen_introduksjon_2018]. 

```{r TKlevel1_interaction_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
m2 <- lm_robust(scale(TK, center = T, scale = T) ~ factor(Gender) * (factor(Trinn) + factor(semester)),
  clusters = factor(studiested), data = data_clean
)
summary(m2)
```

Calculate F-stat by comparing R2 to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- m2$adj.r.squared / model_TK_covariates_l1$adj.r.squared
df1 <- length(data_clean$TK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

The F-statistic indicate that the two models are not significantly different. This means that interaction effects at TK level 1 can be excluded from the rest of the analyses.

#### Level 2

Then I add level 2-variables: studiested

without interaction

```{r TKlevel2_main_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
model_TK_covariates_l2 <- lm_robust(
  scale(TK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) + (factor(semester) + factor(Trinn) + factor(Gender)),    # level 2
  clusters = factor(studiested), data = data_clean
)
summary(model_TK_covariates_l2)
```

```{r}
# main
fstat <- model_TK_covariates_l2$adj.r.squared / model_TK_covariates_l1$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)

# interaction
fstat <- model_TK_covariates_l2$adj.r.squared / m2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

with interaction

Trinn is omitted from interaction since it indicated the weakest interaction. 

```{r TKlevel2_interaction_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
m4 <- lm_robust(
  scale(TK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) * (factor(semester) + factor(Trinn) + factor(Gender)),    # level 2
  clusters = factor(studiested), data = data_clean
)
summary(m4)
```

Some missing data leads to NA. 

```{r}
# interaction
fstat <- m4$adj.r.squared / model_TK_covariates_l2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

The f-statistic indicate no significant differences with or without interaction, so interaction effects at level 2 are excluded from further analysis.

#### Summary

All main variables are included in the further analyses, but no interaction effects. 

### Hierarchical RA for PCK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

#### Level 1

without interaction, only main effects

```{r PCKlevel1_main_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_PCK_covariates_l1 <- lm_robust(PCK ~ factor(Gender) + factor(Trinn) + factor(semester),
  clusters = factor(studiested), data = data_clean
)
summary(model_PCK_covariates_l1)
```

with interaction

```{r PCKlevel1_interaction_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
m2 <- lm_robust(scale(PCK, center = T, scale = T) ~ 
                  factor(semester) * (factor(Gender) + factor(Trinn)),
  clusters = factor(studiested), data = data_clean
)
summary(m2)
```

Calculate F-stat to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- m2$adj.r.squared / model_PCK_covariates_l1$adj.r.squared
df1 <- length(data_clean$PCK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is no significant difference when including interaction effects. They are therefore excluded from further analysis. 

#### Level 2

only main effects

```{r PCKlevel2_main_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
model_PCK_covariates_l2 <- lm_robust(
  scale(PCK) ~ 
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) + (factor(semester) + factor(Trinn) + factor(Gender)),    # level 2
  clusters = factor(studiested), data = data_clean
)
summary(model_PCK_covariates_l2)
```

```{r}
# main
fstat <- model_PCK_covariates_l2$adj.r.squared / model_PCK_covariates_l1$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)

# interaction
fstat <- model_PCK_covariates_l2$adj.r.squared / m2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is no significant difference between level 1 and level 2, indicating no difference between TEIs. 

interaction effects

target grade level is excluded from the interaction effects

```{r PCKlevel2_interaction_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
m4 <- lm_robust(scale(PCK) ~ 
                  factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
                  factor(studiested) * (factor(semester) + factor(Trinn) + factor(Gender)),    # level 2
                clusters = factor(studiested), data=data_clean)
summary(m4)
```

```{r}
fstat <- m4$adj.r.squared / model_PCK_covariates_l2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is no significant difference when including interaction effects.

#### Summary

Only level 1 variables contribute to explain variance in PCK. 

### Hierarchical RA for TPACK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

#### Level 1

Covariates are first added as a block. 

Main effects

```{r level1_main_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_TPACK_covariates_l1 <- lm_robust(
  TPACK ~
    factor(Gender) + factor(Trinn) + factor(semester),
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_covariates_l1)
```

Interaction effects

```{r level1_interaction_paper2}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
m2 <- lm_robust(
  scale(TPACK, center = T, scale = T) ~
    factor(Gender) * (factor(semester) + factor(Trinn)),
  clusters = factor(studiested), data = data_clean
)
summary(m2)
```

Calculate F-stat to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- m2$adj.r.squared / model_TPACK_covariates_l1$adj.r.squared
df1 <- length(data_clean$TPACK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is no significant difference when including interaction effects, so they are omitted from further analysis. 

#### Level 2

Main effects

```{r level2_main_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
model_TPACK_covariates_l2 <- lm_robust(
  scale(TPACK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) + (factor(semester) + factor(Gender)),    # level 2
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_covariates_l2)
```

```{r}
#main
fstat <- model_TPACK_covariates_l2$adj.r.squared / model_TPACK_covariates_l1$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)

# interaction
fstat <- model_TPACK_covariates_l2$adj.r.squared / m2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

Interaction effects

```{r level2_interaction_paper2}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
m4 <- lm_robust(
  scale(TPACK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) * (factor(semester) + factor(Gender)),    # level 2
  clusters = factor(studiested), data = data_clean
)
summary(m4)
```

```{r}
fstat <- m4$adj.r.squared / model_TPACK_covariates_l2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There are no significant interaction effects, so they are excluded from further analysis. 

#### PCK

After the covariates are added as a block, PCK is added. 

```{r PCK_paper2}
# PCK
model_TPACK_PCK <- lm_robust(
  scale(TPACK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +         # level 1
    factor(studiested) * (factor(semester) + factor(Gender)) +    # level 2
    scale(PCK),
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_PCK)

# main
fstat <- model_TPACK_PCK$adj.r.squared / model_TPACK_covariates_l2$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)

# interaction
fstat <- model_TPACK_PCK$adj.r.squared / m4$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is a significant difference when adding PCK as a main effect. 

#### TK

Finally, TK is added. 

```{r TK_paper2}
# TK
model_TPACK_TK <- lm_robust(
  scale(TPACK) ~
    factor(Gender) * (factor(Trinn) + factor(semester)) +        # level 1
    factor(studiested) * (factor(semester) + factor(Gender)) +    # level 2
    scale(PCK) + scale(TK),
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_TK)

fstat <- model_TPACK_TK$adj.r.squared / model_TPACK_PCK$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is a significant difference, when adding TK. 

### Results summarised

Here I reproduce the tables presented in paper 2. The significance values can be found in the f-tests done above. 

```{r}
# table

# TK

mtkcl1rs  <- model_TK_covariates_l1$r.squared
mtkcl1ars <- model_TK_covariates_l1$adj.r.squared

mtkcl2rs  <- model_TK_covariates_l2$r.squared
mtkcl2ars <- model_TK_covariates_l2$adj.r.squared

TK_R2     <- data.frame(
  "R2"    = c(mtkcl1rs, mtkcl2rs),
  "R2adj" = c(mtkcl1ars, mtkcl2ars),
  "diff"  = c(mtkcl1ars, mtkcl2ars - mtkcl1ars)
)

rownames(TK_R2) <- c("Gender, year of study, target grade level", "Teacher education institute")

pander(TK_R2)
```

```{r}
# PCK

mpcl1rs   <- model_PCK_covariates_l1$r.squared
mpcl1ars  <- model_PCK_covariates_l1$adj.r.squared

mpcl2rs   <- model_PCK_covariates_l2$r.squared
mpcl2ars  <- model_PCK_covariates_l2$adj.r.squared

PCK_R2    <- data.frame(
  "R2"    = c(mpcl1rs, mpcl2rs),
  "R2adj" = c(mpcl1ars, mpcl2ars),
  "diff"  = c(mpcl1ars, mpcl2ars - mpcl1ars)
)

rownames(PCK_R2) <- c("Gender, year of study, target grade level", "Teacher education institute")

pander(PCK_R2)
```

```{r}
# TPACK

mtcl1rs  <- model_TPACK_covariates_l1$r.squared
mtcl1ars <- model_TPACK_covariates_l1$adj.r.squared

mtcl2rs  <- model_TPACK_covariates_l2$r.squared
mtcl2ars <- model_TPACK_covariates_l2$adj.r.squared

mtprs    <- model_TPACK_PCK$r.squared
mtpars   <- model_TPACK_PCK$adj.r.squared

mttrs    <- model_TPACK_TK$r.squared
mttars   <- model_TPACK_TK$adj.r.squared

TPACK_R2 <- data.frame(
  "R2" = c(mtcl1rs, mtcl2rs, mtprs, mttrs),
  "R2adj" = c(mtcl1ars, mtcl2ars, mtpars, mttars),
  "diff" = c(mtcl1ars, mtcl2ars - mtcl1ars, 
             mtpars - mtcl2ars, mttars - mtpars)
)

rownames(TPACK_R2) <- c("Gender, year of study, target grade level", "Teacher education institute", "PCK", "TK")

pander(TPACK_R2)
```

## Reanalysis of OLS

A reanalysis of the OLS is done here, due to some methodical reconsiderations after a closer look at the MLM. The dataset is slightly closer to the rawdata (3 NAs were reset to other, as in the original dataset). The order of the variables are also slightly different (TEIs are introduced before covariates). Finally, interaction effects are not included, as they were in paper 2. The statistical tests suggested that the interaction effects were non-significant. Otherwise, the analysis is similar to paper 2. 

### Reload data

```{r}
# ref: https://www.statology.org/clear-environment-in-r/ [5.9.2024]
#clear all data frames from environment
rm(list=ls(all=TRUE)[sapply(mget(ls(all=TRUE)), class) == "data.frame"])
```

Then I reload the dataset from file. 

```{r load_data_reanalysis}
# Rdata-file contains reduced / prepared datasets
load(file="../data/processed_data/tpack-TRELIS-Q_complete_2023-paper2.Rdata")
```

Then I recenter the data.

```{r}
data_TRELIS_Q[,unlist(TPACK_trelis_q)] <- data_TRELIS_Q[,unlist(TPACK_trelis_q)] - 3 
```

And add some missing information.

```{r}
# identify NA as studiested 5(?) 
data_TRELIS_Q[data_TRELIS_Q$studiested == "Institute3","Trinn"] <- "Trinn 5-10"
```

NMAR are removed. 

```{r fix_missing_2, eval=T}
# remove NMAR + Institute9 (19)
data_clean <- data_TRELIS_Q[-c(19,34,44,45,46,95,102),] 
```

```{r}
scores_v23 <- scoreItems(TPACK_trelis_q, data_clean)

describe(scores_v23$scores)

# constructs for multiple regression
TK_v23    <- scores_v23$scores[,"TK"]
PCK_v23   <- scores_v23$scores[,"PCK"]
TPACK_v23 <- scores_v23$scores[,"TPACK"]

# add constructs to data.frame
data_clean$TK    <- TK_v23
data_clean$PCK   <- PCK_v23
data_clean$TPACK <- TPACK_v23
```

### Hierarchical RA for TK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

Interaction effects are examined by calculating F-statistics to see if models with and without interaction are significantly different. 

#### baseline model (nullmodell)

```{r TK_baseline}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_TK_baseline <- lm_robust(TK ~ factor(studiested), 
                clusters = factor(studiested), data=data_clean)
summary(model_TK_baseline)
```

#### Level 1

First, all covariates at the individual PST level 1 (i.e., gender, target grade level and year of study) are introduced as a block. 

Without interaction

```{r TKlevel1_main}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_TK_level1 <- lm_robust(TK ~ factor(studiested) + factor(Gender) + (factor(Trinn) + factor(semester)), 
                clusters = factor(studiested), data=data_clean)
summary(model_TK_level1)
```

Calculate F-stat by comparing R2 to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- model_TK_level1$adj.r.squared / model_TK_baseline$adj.r.squared
df1 <- length(data_clean$TK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

The F-statistic indicate that the two models are not significantly different. This means that level1 effects do not contribute significantly to the variance.

### Hierarchical RA for PCK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

#### Baseline

```{r PCKlevel2_main}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
model_PCK_baseline <- lm_robust(
  PCK ~ 
    factor(studiested),                                 # level 2
  clusters = factor(studiested), data = data_clean
)
summary(model_PCK_baseline)
```

#### Level 1

without interaction, only main effects

```{r PCKlevel1_main}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_PCK_level1 <- lm_robust(PCK ~ factor(studiested) + factor(Gender) + factor(Trinn) + factor(semester),
  clusters = factor(studiested), data = data_clean
)
summary(model_PCK_level1)
```

Calculate F-stat to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- model_PCK_level1$adj.r.squared / model_PCK_baseline$adj.r.squared
df1 <- length(data_clean$PCK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

There were significant differences when including covariates. 

### Hierarchical RA for TPACK

Level 1: students  
Level 2: institution

We are using cluster corrected standard errors to correct for clustering on institution.

Add student covariates

#### Baseline

```{r level2_main}
# studiested; Institute1 velges som referansekategori siden den har lavest TPACK-verdi av alle
model_TPACK_baseline <- lm_robust(
  TPACK ~
    factor(studiested),                                 # level 2
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_baseline)
```

#### Level 1

Covariates are first added as a block. 

Main effects

```{r level1_main}
# kovariater; we use scale to standardize when using interaction effects
# sjekk: er det riktig å skalere?
model_TPACK_level1 <- lm_robust(
  TPACK ~
    factor(studiested) + factor(Gender) + factor(Trinn) + factor(semester),
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_level1)
```

Calculate F-stat to see if they are significantly different

```{r}
# source: https://www.statology.org/how-to-calculate-the-p-value-of-an-f-statistic-in-r/
# source: p. 257 i Howitt & Cramer, 2014
fstat <- model_TPACK_level1$adj.r.squared / model_TPACK_baseline$adj.r.squared
df1 <- length(data_clean$TPACK) - 1
df2 <- df1
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is no significant difference when including covariates. 

#### PCK

After the covariates are added as a block, PCK is added. 

```{r PCK}
# PCK
model_TPACK_PCK <- lm_robust(
  TPACK ~
    factor(Gender) + factor(Trinn) + factor(semester) + # level 1
    factor(studiested) +                                # level 2
    PCK,
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_PCK)

# main
fstat <- model_TPACK_PCK$adj.r.squared / model_TPACK_level1$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)

```

There is a significant difference when adding PCK as a main effect. 

#### TK

Finally, TK is added. 

```{r TK}
# TK
model_TPACK_TK <- lm_robust(
  TPACK ~
    factor(Gender) + factor(Trinn) + factor(semester) + # level 1
    factor(studiested) +                                # level 2
    PCK + TK,
  clusters = factor(studiested), data = data_clean
)
summary(model_TPACK_TK)

fstat <- model_TPACK_TK$adj.r.squared / model_TPACK_PCK$adj.r.squared
pf(fstat, df1, df2, lower.tail = FALSE)
```

There is a significant difference, when adding TK. 

### Results summarised

The results differ somewhat from paper 2 in that some interaction effects are excluded, which was included in the analysis done for paper 2. The main trends are however similar. 

```{r}
# table

# TK

mtkcl1rs  <- model_TK_baseline$r.squared
mtkcl1ars <- model_TK_baseline$adj.r.squared

mtkcl2rs  <- model_TK_level1$r.squared
mtkcl2ars <- model_TK_level1$adj.r.squared

TK_R2     <- data.frame(
  "R2"    = c(mtkcl1rs, mtkcl2rs),
  "R2adj" = c(mtkcl1ars, mtkcl2ars),
  "diff"  = c(mtkcl1ars, mtkcl2ars - mtkcl1ars)
)

rownames(TK_R2) <- c("Teacher education institute", "Gender, year of study, target grade level")

pander(TK_R2)
```

```{r}
# PCK

mpcl1rs   <- model_PCK_baseline$r.squared
mpcl1ars  <- model_PCK_baseline$adj.r.squared

mpcl2rs   <- model_PCK_level1$r.squared
mpcl2ars  <- model_PCK_level1$adj.r.squared

PCK_R2    <- data.frame(
  "R2"    = c(mpcl1rs, mpcl2rs),
  "R2adj" = c(mpcl1ars, mpcl2ars),
  "diff"  = c(mpcl1ars, mpcl2ars - mpcl1ars)
)

rownames(PCK_R2) <- c("Teacher education institute", "Gender, year of study, target grade level")

pander(PCK_R2)
```

```{r}
# TPACK

mtcl1rs  <- model_TPACK_baseline$r.squared
mtcl1ars <- model_TPACK_baseline$adj.r.squared

mtcl2rs  <- model_TPACK_level1$r.squared
mtcl2ars <- model_TPACK_level1$adj.r.squared

mtprs    <- model_TPACK_PCK$r.squared
mtpars   <- model_TPACK_PCK$adj.r.squared

mttrs    <- model_TPACK_TK$r.squared
mttars   <- model_TPACK_TK$adj.r.squared

TPACK_R2 <- data.frame(
  "R2" = c(mtcl1rs, mtcl2rs, mtprs, mttrs),
  "R2adj" = c(mtcl1ars, mtcl2ars, mtpars, mttars),
  "diff" = c(mtcl1ars, mtcl2ars - mtcl1ars, 
             mtpars - mtcl2ars, mttars - mtpars)
)

rownames(TPACK_R2) <- c("Teacher education institute", "Gender, year of study, target grade level", "PCK", "TK")

pander(TPACK_R2)
```

Level 1: gender, target grade level  
Level 2: year of study, institute

Burde semester vært en level 2 variabel, siden det er mer en egenskap ved instituttet enn studenten? 

Spørsmålet er om forskjeller på semester skyldes endringer på instituttet (level 2) eller endringer i studentmassen (level 1)? Både-og? Samspill på tvers av nivåer!


## Multi-level modeling with cross-level interaction effects

When the data is nested, multi-level modeling can be used. However, when the number of level 2-units is below 10, as it is in our dataset (we have only 5 TEIs), OLS with cluster corrected standard errors can be used. I, however, do a MLM here to compare with the OLS results. MLM is only done for TPACK as dependent variable to illustrate the method.

The r package NLME [@pinheiro_nlme_2023] is used for the analysis. 

### Baseline model

First, the baseline model is calculated as a reference and to find the ICC.

```{r}
# baseline model / nullmodell

# REML is used for parameter estimation
model_MLM_baseline <- lme(TPACK~1, data=data_clean, method="REML", na.action="na.omit", random= ~1|studiested) 

# ML is used for model fit
model_MLM_baseline_fit <- lme(TPACK~1, data=data_clean, method="ML", na.action="na.omit", random= ~1|studiested)

summary(model_MLM_baseline)
summary(model_MLM_baseline_fit)
```

```{r}
# ICC
nu_00 <- var(ranef(model_MLM_baseline)) # intercept (i.e., TEIs)
nu_e  <- var(resid(model_MLM_baseline)) # residuals (i.e., PSTs)
ICC   <- nu_00 / (nu_00 + nu_e)
ICC
```

30 % av variansen i TPACK ligger på nivå 2. Dette er større enn den anbefalte grensen på 5 %. Vurder om OLS-regresjon med klyngekorrigert standardfeil egner seg bedre enn flernivåanalyse [@christophersen_introduksjon_2018] (p. 109).

```{r}
# effektiv utvalgsstørrelse
n_e <- 147 / (1 + ((147 / 5) - 1) * ICC)
n_e
```

Utvalgsstørrelsen korrigert for avhengighet er lik 15. 

### Level 1 model (random intercept)

The level 1 model extends the baseline model by including the covariates. 

#### Level 1 variables

```{r}
# REML is used for parameter estimation
model_MLM_level1 <- lme(TPACK~Gender + semester + Trinn, data=data_clean, method="REML", na.action="na.omit", random= ~1|studiested) 

# ML is used for model fit
model_MLM_level1_fit <- lme(TPACK~Gender + semester + Trinn, data=data_clean, method="ML", na.action="na.omit", random= ~1|studiested) 

summary(model_MLM_level1)
summary(model_MLM_level1_fit)
```

Er level 1-modellen bedre enn nullmodellen?

```{r eval=T}
anova(model_MLM_baseline_fit, model_MLM_level1_fit)
```

#### Level 2 variables

Since Level 2 variables are unique to MLM, and the solution does not converge, level 2 analysis is not done here. 

La kovariatene variere mellom studiesteder

```{r eval=F}
# REML is used for parameter estimation
model_level2 <- lme(TPACK~Gender + semester + Trinn, data=data_clean, method="REML", na.action="na.omit", random= ~ semester|studiested) 

# ML is used for model fit
model_level2_fit <- lme(TPACK~Gender + semester + Trinn, data=data_clean, method="ML", na.action="na.omit", random= ~ semester|studiested) 

summary(model_level2)
summary(model_level2_fit)
```

Er level 2-modellen bedre enn level 1?

```{r eval=F}
anova(model_level2_fit, model_MLM_level1_fit)
```

### PCK

```{r}
# grand mean centering: scale(TK, center = T, scale = F)

data_clean$PCK_cent <- scale(data_clean$PCK, center = T, scale = F)
data_clean$TK_cent  <- scale(data_clean$TK, center = T, scale = F)

# REML is used for parameter estimation
model_MLM_PCK <- lme(TPACK~Gender + semester + Trinn + PCK_cent, data=data_clean, method="REML", na.action="na.omit", random= ~1|studiested) 

# ML is used for model fit
model_MLM_PCK_fit <- lme(TPACK~Gender + semester + Trinn + PCK_cent, data=data_clean, method="ML", na.action="na.omit", random= ~1|studiested) 

summary(model_MLM_PCK)
summary(model_MLM_PCK_fit)
```

```{r eval=T}
anova(model_MLM_PCK_fit, model_MLM_level1_fit)
```

### TK

```{r}
# REML is used for parameter estimation
model_MLM_TK <- lme(TPACK~Gender + semester + Trinn + PCK_cent + TK_cent, data=data_clean, method="REML", na.action="na.omit", random= ~1|studiested) 

# ML is used for model fit
model_MLM_TK_fit <- lme(TPACK~Gender + semester + Trinn + PCK_cent + TK_cent, data=data_clean, method="ML", na.action="na.omit", random= ~1|studiested) 

summary(model_MLM_TK)
summary(model_MLM_TK_fit)
```

```{r eval=T}
anova(model_MLM_PCK_fit, model_MLM_TK_fit)
```

## Comparison of OLS and MLM

### Comparison of variance

I follow @christophersen_introduksjon_2018 (p. 115) and use the variance estimates as an indicator of R2. 

```{r}
# MLM
# variance baseline
nu_00_baseline <- var(ranef(model_MLM_baseline)) # intercept (i.e., TEIs)
nu_e_baseline  <- var(resid(model_MLM_baseline)) # residuals (i.e., PSTs)

# variance level 1
nu_00_level1 <- var(ranef(model_MLM_level1)) # intercept (i.e., TEIs)
nu_e_level1  <- var(resid(model_MLM_level1)) # residuals (i.e., PSTs)

# variance PCK
nu_00_PCK <- var(ranef(model_MLM_PCK)) # intercept (i.e., TEIs)
nu_e_PCK  <- var(resid(model_MLM_PCK)) # residuals (i.e., PSTs)

# variance TK
nu_00_TK <- var(ranef(model_MLM_TK)) # intercept (i.e., TEIs)
nu_e_TK  <- var(resid(model_MLM_TK)) # residuals (i.e., PSTs)

# OLS
mtcl1ars <- model_TPACK_baseline$adj.r.squared
mtcl2ars <- model_TPACK_level1$adj.r.squared
mtpars   <- model_TPACK_PCK$adj.r.squared
mttars   <- model_TPACK_TK$adj.r.squared

# table of difference in variance

table_variance <- data.frame(
  c(nu_e_baseline, (nu_e_baseline - nu_e_level1) / nu_e_baseline, (nu_e_level1 - nu_e_PCK) / nu_e_level1, (nu_e_PCK - nu_e_TK) / nu_e_PCK),
  c(nu_00_baseline, (nu_00_baseline - nu_00_level1) / nu_00_baseline, (nu_00_baseline - nu_00_PCK) / nu_00_baseline, (nu_00_baseline - nu_00_TK) / nu_00_baseline),
  c(mtcl1ars, mtcl2ars - mtcl1ars, mtpars - mtcl2ars, mttars - mtpars)
  )

rownames(table_variance) <- c("TEI", "covariates", "PCK", "TK")
colnames(table_variance) <- c("MLM Level 1 % var", "MLM Level 2 % var", "OLS reanalysis diff R2")

pander(table_variance)
```

The variance differ somewhat from the standard deviation (when squared) reported in the summary of the MLMs. Why? Is the OLS a kind of average of the MLM, which is separated into level 1 and level 2?

# Discussion and conclusion

I was able to replicate the results discussed in @karlsen_assessing_2024. 

The reanalysis using OLS gave similar results as for paper 2. Only TEIs explained variance in TK, not the covariates. The covariates did however significantly explain the variance in PCK, but the TEIs did not (or to a small degree, only 3%). The variance in TPACK was significantly explained by TEI, PCK and TK, not the covariates. 

The results in paper 2 indicated that the covariates contributed to explain the variance in TPACK. The reanalysis done here, suggest that this may be due to the order in which the variables were added to the model being tested. If I follow the order used in the MLM, the reanalysis suggests that the covariates do not contribute to TPACK. 

The MLM gave supporting results. Including the covariates did not improve the model, whereas including PCK and TK did. The variance at level 2 (between TEIs) was due to TK, not PCK or covariates, that is, there were significant differences in TK between TEIs. At level 1 (between PSTs) 6% of the variance were due to the covariates, 17 % due to PCK and 55 % due to TK. 

The OLS reanalysis suggested that 30 % of the variance in TPACK was due to TEIs, 11 % due to PCK and 32 % due to TPACK. The covariates did not contribute to the variance in TPACK. Even though the percentages differ between the OLS and the MLM, they show the same trends. The different percentages may be due to how R2 (or difference in variance) is calculated differently in OLS and MLM. 

# References

<!-- citation(package) -->

<div id="refs"></div>

<!-- source: https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html 

# (APPENDIX) Appendix {-} -->

# Session info
<!-- # ref.: https://intro2r.com/proj_doc.html -->
<!-- #sessionInfo() -->

```{r}
xfun::session_info()
```
