---
title: "Paper 1: Instrument development"
author: "Niklas Karlsen, OsloMet, Norway, e-mail: niklaska@oslomet.no"
date: "2024-05-28"
bibliography: "../data/meta_data/references.bib"
csl: "../scripts/university-of-gothenburg-apa-7th-edition-swedish-legislations.csl" # (source: https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html)
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), '../output/Paper1.html')) })
---

# Introduction

The main purpose of this Rmd-script is to reproduce the results in paper 1. The whole process from reducing the raw data to doing the EFA and CFA is discussed. The document is inspired by the idea of a computational essay [@odden_using_2023].

The development of a measure usually follows three stages [@boateng_best_2018]:

1. Item development
2. Scale development
3. Scale evaluation

The first stage is described in @karlsen_assessing_2024. This computational essay describes the analysis behind the results in this paper, and emphasises the quantitative analyses done in the final two stages. This concerns item reduction and extraction of factors (EFA) in stage two, and test of dimensionality (CFA) and tests of reliability and validity in stage three. 

## Imports

```{r}
# libraries

library(readODS)                            # read .ods-files. Kilde: https://github.com/ropensci/readODS/
library(readxl)                             # read .xlsx-files. Kilde: https://readxl.tidyverse.org/

library(pander)                             # print pretty tables
library(dplyr)                              # rename columns
library(tidyr)                              # pivot_longer

library(ggplot2)

# multicollinearity checks
library("corrplot")                         # multicollinearity 
library(car)                                # vif       
library("olsrr")                            # vif

library(psych)                              # for skew
library(mice)                               # for missing 

```

# Stage 2 

From stage 2 Boateng et al. (2013) describes three steps which will be discussed here: step 4 (gather data), step 5 (item reduction) and step 6 (factor extraction, i.e., EFA). 

## Step 4: Data gathering / cleaning

This step concerns data gathering for the EFA and the CFA using separate samples for each analysis. The recommended sample size is 10 respondents per item and/or 200-300 observations in total (Boateng et al., 2018). The sample size is discussed more closely in @karlsen_assessing_2024. 

Data were collected for two pilots (EFA) and the CFA. The three datasets were reduced individually. 

The data for the first pilot were collected using two almost identical questionnaires. Four of the items were however slightly modified to use the term "coding" instead of "programming". "Programming" is used in the final published version, so this is what we choose also when reducing the dataset. 

All respondents were explicitly asked to agree to their answers being treated in the research. All answered "yes", except a few that answered blank, perhaps forgetting to check the answer, as it was not obligatory. We interpreted blank answers as "yes", although strictly speaking this should probably be interpreted as "no" to be on the safe side. For the respondents who answered blank to the qeustion to agree to participate in the research, all the questions in the questionnaire were filled in. The data contained no identifying information, and thus were anonymous. 

The raw data were downloaded from nettskjema.no in the xlsx-format and transformed to the Rdata-format in Rstudio. To get enough respondents for the EFA, the pilot data were combined with data from the learning sequence we developed (codename: emne2). 

* pilot: data-257861-2022-06-15-1302-utf.xlsx
* emne2: predata-257846-2022-03-28-1311-utf.ods
* trelis-q pilot: Datafil-utproving-trelis-q-institute4-institute1-aug2022.xlsx
* TRELIS-Q (dec-feb): data-trelis-q-tatt-ut-2feb2023.xlsx

Pilot is the pilot for the questionnaire published in @karlsen_assessing_2024. trelis-q pilot is the pilot for the TRELIS-Q questionnaire. The pilot was incorporated into TRELIS-Q. TRELIS-Q is a larger questionnaire containing questions related to the three working packages of TRELIS related to inquiry, programming and professional development. My work is related to the programming work package (WP5). The emne2-dataset was saved in the ods-format as the participant names were anonymized. 

The aim is to create the following dataset:

* data_TPACK_pilot, which uses TK, CK, etc for column names
* data_TRELIS_Q

data_TPACK_pilot will be used for the EFA, while data_TRELIS_Q will be used for the CFA.

The dataframe is built up with the different datasets as follows:

* df[1:21,] =   emne2_pre        (n=21)  
* df[22:41,] =  emne2_post       (n=20)  
* df[42:57,] =  pilot            (n=16)  
* df[58:105,] = pilot trelis_q   (n=48)  

### Load datasets

```{r load_emne2}
folder_emne2         <- "../data/rawdata/"

pre_emne2            <- "predata-257846-2022-03-28-1311-utf.ods"
post_emne2           <- "postdata-257846-2022-05-10-1048-utf.ods"

path_pre_emne2       <- paste(folder_emne2, pre_emne2, sep='')
path_post_emne2      <- paste(folder_emne2, post_emne2, sep='')
 
data_pre_emne2       <- read_ods(path_pre_emne2)
data_post_emne2      <- read_ods(path_post_emne2)
```

```{r load_pilot}
folder_pilot          <- "../data/rawdata/"
pilot                 <- "data-257861-2022-06-15-1302-utf.xlsx"

path_pilot            <- paste(folder_pilot, pilot, sep='')

data_pilot            <- read_excel(path_pilot)
```

```{r load_pilot_trelis_q}
folder_pilot_trelis_q <- "../data/rawdata/"
pilot_trelis_q        <- "Datafil-utproving-trelis-q-institute4-institute1-aug2022.xlsx"

path_pilot_trelis_q   <- paste(folder_pilot_trelis_q, pilot_trelis_q, sep='')

data_pilot_trelis_q   <- read_excel(path_pilot_trelis_q, sheet=1)
```

```{r load_TRELIS_Q}
folder_trelis_q       <- "../data/rawdata/"
trelis_q              <- "data-trelis-q-tatt-ut-2feb2023.xlsx"

path_trelis_q         <- paste(folder_trelis_q, trelis_q, sep='')

data_trelis_q         <- read_excel(path_trelis_q) #, sheet=2)
```

### Data cleaning

Rename items using the term "coding" so they use "programming" instead to enable merging of the datasets.

#### emne2

```{r emne2_cleaning}
# keep some columns
data_pre_emne2  <- rename(data_pre_emne2,
                             "Subject" =
                             "Hva heter du (fornavn og etternavn)?")
data_post_emne2 <- rename(data_post_emne2,
                             "Subject" =
                             "Hva heter du (fornavn og etternavn)?")
data_pre_emne2  <- rename(data_pre_emne2,
                             "Trinn" =
                             "Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?")
data_post_emne2 <- rename(data_post_emne2,
                             "Trinn" =
                             "Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?")
data_pre_emne2  <- rename(data_pre_emne2,
                             "andre_fag" =
                             "Hva er ditt andre fag?")
data_post_emne2 <- rename(data_post_emne2,
                             "andre_fag" =
                             "Hva er ditt andre fag?")

# add institute and semester
data_pre_emne2$studiested      <- rep("Institute4",21)
data_pre_emne2$semester        <- rep(8,21)      # 8. semester (syklus 2, vår)
data_post_emne2$studiested     <- rep("Institute4",20)
data_post_emne2$semester       <- rep(8,20)      # 8. semester

# add full_treatment; 1 = deltok på all undervisning; 0 = ikke all undv.
data_pre_emne2$full_treatment  <- rep(1,21)
data_post_emne2$full_treatment <- rep(1,20)
# de som ikke deltok på alt
data_pre_emne2[data_pre_emne2$Subject   == "Ester","full_treatment"]  <- 0
data_pre_emne2[data_pre_emne2$Subject   == "Harald","full_treatment"] <- 0
data_pre_emne2[data_pre_emne2$Subject   == "Olava","full_treatment"]  <- 0
data_post_emne2[data_post_emne2$Subject == "Ester","full_treatment"]  <- 0
data_post_emne2[data_post_emne2$Subject == "Harald","full_treatment"] <- 0
data_post_emne2[data_post_emne2$Subject == "Olava","full_treatment"]  <- 0

# add gender; 0 = male; 1 = female
data_pre_emne2$Gender <- c("Kvinne", "Mann", "Kvinne", "Mann", "Kvinne", "Mann", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Mann", "Mann", "Kvinne", "Mann", "Kvinne", "Mann", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Kvinne")
data_post_emne2$Gender <-c("Kvinne", "Mann", "Mann", "Mann", "Mann", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Kvinne", "Mann", "Kvinne", "Kvinne", "Mann", "Mann", "Kvinne", "Kvinne")

# bytt rekkefølgen på noen items
data_pre_emne2  <- data_pre_emne2  %>% relocate(Trinn,      .before = "Subject")
data_post_emne2 <- data_post_emne2 %>% relocate(Trinn,      .before = "Subject")
data_pre_emne2  <- data_pre_emne2  %>% relocate(Gender,     .after  = "Subject")
data_post_emne2 <- data_post_emne2 %>% relocate(Gender,     .after  = "Subject")
data_pre_emne2  <- data_pre_emne2  %>% relocate(andre_fag,  .before = "Subject")
data_post_emne2 <- data_post_emne2 %>% relocate(andre_fag,  .before = "Subject")
data_pre_emne2  <- data_pre_emne2  %>% relocate(studiested, .before = "Trinn")
data_post_emne2 <- data_post_emne2 %>% relocate(studiested, .before = "Trinn")
data_pre_emne2  <- data_pre_emne2  %>% relocate(semester,   .before = "Trinn")
data_post_emne2 <- data_post_emne2 %>% relocate(semester,   .before = "Trinn")
data_pre_emne2  <- data_pre_emne2  %>% relocate(full_treatment, .before = "studiested")
data_post_emne2 <- data_post_emne2 %>% relocate(full_treatment, .before = "studiested")
```

Rename items

```{r emne2_rename_items}
ren_emne2 <- function (data_name) {rename(data_name, 
"TK2"    = "Jeg kan lage algoritmer ved hjelp av penn og papir og flytdiagrammer.",
"TK1"    = "Jeg kan bruke algoritmisk tenkning når jeg lager dataprogrammer.",
"TK3"    = "Jeg kan lage dataprogrammer ved å bruke blokk-basert programmering.",        
"TK4"    = "Jeg kan lage dataprogrammer ved å bruke tekst-basert programmering.",             
"TK5"    = "Jeg kan bruke variabler, når jeg programmerer.",
"TK6"    = "Jeg kan bruke vilkår (if, else), når jeg programmerer.",
"TK7"    = "Jeg kan bruke løkker (for, while), når jeg programmerer.",
"TK8"    = "Jeg kan lage dataprogrammer som inneholder funksjoner.",
"CK1"    = "Jeg forstår det faglige innholdet i naturfag som handler om energi og materie.",                                        
"CK2"    = "Jeg forstår det faglige innholdet i naturfag som handler om jorda og livet på jorda.",                                         
"CK3"    = "Jeg forstår det faglige innholdet i naturfag som handler om kropp og helse.",                                          
"CK4"    = "Jeg forstår hvordan ulike typer teknologi virker, f.eks. hvordan teknologi kan styres med dataprogrammer.",
"CK5"    = "Jeg har kunnskaper om naturvitenskapelige tenkemåter og praksiser.",                                        
"TCK1"   = "Jeg kan programmere enkle teknologiske systemer som består av deler som virker sammen.",                                             
"TCK2"   = "Jeg kan bruke programmering og modellering til å utvikle roboter og mikrokontrollere, f.eks. micro:bit.",
"TCK3"   = "Jeg kan utvikle modeller av naturfaglige fenomener ved hjelp av programmering og simulering.",                                              
"TCK4"   = "Jeg kan bruke programmering til å utforske naturfaglige fenomener.",                                                   
"PK1"    = "Jeg vet hvordan jeg kan støtte elevenes refleksjon over egen læring.",                                              
"PK2"    = "Jeg vet hvordan jeg kan støtte elevene emosjonelt i deres læring, f.eks deres utholdenhet, evne til å arbeide målrettet og takle motgang.",
"PK3"    = "Jeg vet hvordan jeg kan støtte elevene sosialt i deres læring, f.eks deres nysgjerrighet, kreativitet og samarbeidsevne.",
"PK4"    = "Jeg vet hvordan jeg kan tilpasse utfordringer til elevene.",
"PK5"    = "Jeg vet hvordan jeg kan tilpasse tilbakemeldinger til elevene.",
"PK6"    = "Jeg vet hvordan jeg kan bruke vurdering til å støtte elevene underveis i deres læring.",
"TPK1"   = "Jeg vet hvordan jeg kan bruke programmering på måter som beriker undervisningen.",                                          
"TPK2"   = "Jeg vet hvordan jeg kan bruke programmering på måter som støtter elevenes læring.",                                           
"TPK3"   = "Jeg vet hvordan jeg kan tilpasse bruken av programmering til forskjellige undervisningsaktiviteter.",
"TPK4"   = "Jeg tenker kritisk gjennom hvordan jeg kan bruke programmering i undervisningen.",                                          
"TPK5"   = "Jeg vet hvordan jeg kan legge frem programmering på måter som motiverer for læring.",                                             
"PCK1"   = "Jeg vet hvordan jeg kan legge til rette for elevenes begrepslæring i naturfag.",                                        
"PCK2"   = "Jeg vet hvordan jeg kan støtte elevene i å utvikle kritisk tenkning og argumentasjonsferdigheter i naturfag.",
"PCK3"   = "Jeg vet hvordan jeg kan bruke utforskende arbeidsmåter i naturfag.",                                                           
"PCK4"   = "Jeg vet hvordan jeg kan bruke modellering som arbeidsmåte i naturfag.",                                    
"PCK5"   = "Jeg vet hvordan jeg kan vurdere elevenes måloppnåelse på ulike måter i naturfag.",                                            
"TPACK1" = "Jeg vet hvordan jeg kan motivere elevene for å bruke programmering til å lære naturfag, for eksempel ved å knytte det til elevenes interesser eller vise hvilken relevans det kan ha.",
"TPACK2" = "Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå mer av naturfaglige begreper og fenomener.",
"TPACK3" = "Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå mer av naturvitenskapelige tenkemåter og praksiser.",                                     
"TPACK4" = "Jeg vet hvordan jeg kan bruke programmering i naturfag til å lære elever hvordan teknologiske systemer fungerer.",
"TPACK5" = "Jeg føler meg klar til å bruke programmering til å undervise naturfag",
"XK1"    = "Jeg vet hvilke utfordringer elevene kan ha når de programmerer.",
"XK2"    = "Jeg har kunnskap om elevers ulike forutsetninger for å ta i bruk programmering.",                                          
"XK3"    = "Jeg vet hvordan programmering i naturfag bidrar til skolens samfunnsoppdrag.",                                               
"XK4"    = "Jeg kan være en ressursperson for kollegaene i skolen når det gjelder programmering i naturfag",
"XK5"    = "Jeg vet hvordan bruk av programmeringsteknologi kan påvirke læringssituasjonen i klasserommet.",
"XK6"    = "Jeg vet hvordan jeg kan lede en undervisningssituasjon i et klasserom der programmering er en sentral aktivitet.")
 }

data_pre_emne2_ren  <- ren_emne2(data_pre_emne2)
data_post_emne2_ren <- ren_emne2(data_post_emne2)

# select relevant questions
data_pre_emne2_ren  <- data_pre_emne2_ren [,5:55]
data_post_emne2_ren <- data_post_emne2_ren[,5:55]
```

The order of the two first questions was switched between emne2 and the pilot. Correct this. Use pilot as correct order.

* TK1: Jeg kan bruke algoritmisk tenkning når jeg lager kode.
* TK2: Jeg kan lage algoritmer ved hjelp av penn og papir og flytdiagrammer.

```{r emne2_switch_order_TK1_2}
data_pre_emne2_ren  <- data_pre_emne2_ren  %>% relocate(TK2, .after = TK1)
data_post_emne2_ren <- data_post_emne2_ren %>% relocate(TK2, .after = TK1)
```

#### pilot

One of the respondents chose the wrong institution, because their institution lacked amongst the options available. This was later corrected in the online questionnaire. I therefore have to change the affiliation of row 12 (NR 21571938) from Institute4 to Institute5, and "hovedfag" from Matematikk to Naturfag. (This is documented through the e-post correspondence with Institute5, which show the time this happened.)

```{r pilot_correct_entry}
# row number was found with View(data_pilot)
# column number was found with colnames(data_pilot)
data_pilot[12,50] <- "Institute5"
data_pilot[12,52] <- "Naturfag"
data_pilot[2,50]  <- "Institute7"  # Institute8 deltok ikke
```

```{r pilot_cleaning}
# rename columns
data_pilot <- rename(data_pilot,
                             "andre_fag" = 
                             "Hva er ditt hovedfag?")

data_pilot <- rename(data_pilot,
                             "Trinn" =
                             "Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10 eller tar du videreutdanning?")

data_pilot <- rename(data_pilot,
                             "studiested" = 
                             "Hvilket studiested studerer du ved?")

# add semester
data_pilot$semester                                        <- rep(0,16)
data_pilot$semester[data_pilot$studiested == "Institute6"] <- 6 
data_pilot$semester[data_pilot$studiested == "Institute4"] <- 4 
# Institute7/8, ?. semester 2/3?
data_pilot$semester[data_pilot$studiested == "Institute5"] <- 8 

# reorder some columns
data_pilot <- data_pilot %>% relocate(andre_fag,  .before = "Jeg kan bruke algoritmisk tenkning når jeg lager kode.")
data_pilot <- data_pilot %>% relocate(Trinn,      .before = "andre_fag")
data_pilot <- data_pilot %>% relocate(studiested, .before = "Trinn")
data_pilot <- data_pilot %>% relocate(semester,   .before = "Trinn")
```

```{r pilot_rename}
data_pilot_ren <- data_pilot %>% rename(
"TK1"    = "Jeg kan bruke algoritmisk tenkning når jeg lager kode.",
"TK2"    = "Jeg kan lage algoritmer ved hjelp av penn og papir og flytdiagrammer.",
"TK3"    = "Jeg kan lage kode ved å bruke blokk-basert programmering.",        
"TK4"    = "Jeg kan lage kode ved å bruke tekst-basert programmering.",             
"TK5"    = "Jeg kan bruke variabler, når jeg programmerer.",
"TK6"    = "Jeg kan bruke vilkår (if, else), når jeg programmerer.",
"TK7"    = "Jeg kan bruke løkker (for, while), når jeg programmerer.",
"TK8"    = "Jeg kan lage dataprogrammer som inneholder funksjoner. (Funksjoner kan for eksempel være noen linjer med kode som har blitt skilt ut som en egen algoritme som kan gjenbrukes, f.eks. fordi den beskriver noe som gjøres ofte i programmet.)",
"CK1"    = "Jeg forstår det faglige innholdet i naturfag som handler om energi og materie.",                                        
"CK2"    = "Jeg forstår det faglige innholdet i naturfag som handler om jorda og livet på jorda.",                                         
"CK3"    = "Jeg forstår det faglige innholdet i naturfag som handler om kropp og helse.",                                          
"CK4"    = "Jeg forstår hvordan ulike typer teknologi virker, f.eks. hvordan teknologi kan styres med dataprogrammer.",
"CK5"    = "Jeg har kunnskaper om naturvitenskapelige tenkemåter og praksiser.",                                        
"TCK1"   = "Jeg kan programmere enkle teknologiske systemer som består av deler som virker sammen.",                                             
"TCK2"   = "Jeg kan bruke programmering og modellering til å utvikle roboter og mikrokontrollere, f.eks. micro:bit.",
"TCK3"   = "Jeg kan utvikle modeller av naturfaglige fenomener ved hjelp av programmering og simulering.",                                              
"TCK4"   = "Jeg kan bruke programmering til å utforske naturfaglige fenomener.",                                                   
"PK1"    = "Jeg vet hvordan jeg kan støtte elevenes refleksjon over egen læring.",                                              
"PK2"    = "Jeg vet hvordan jeg kan støtte elevene emosjonelt i deres læring, f.eks deres utholdenhet, evne til å arbeide målrettet og takle motgang.",
"PK3"    = "Jeg vet hvordan jeg kan støtte elevene sosialt i deres læring, f.eks deres nysgjerrighet, kreativitet og samarbeidsevne.",
"PK4"    = "Jeg vet hvordan jeg kan tilpasse utfordringer til elevene.",
"PK5"    = "Jeg vet hvordan jeg kan tilpasse tilbakemeldinger til elevene.",
"PK6"    = "Jeg vet hvordan jeg kan bruke vurdering til å støtte elevene underveis i deres læring.",
"TPK1"   = "Jeg vet hvordan jeg kan bruke programmering på måter som beriker undervisningen.",                                          
"TPK2"   = "Jeg vet hvordan jeg kan bruke programmering på måter som støtter elevenes læring.",                                           
"TPK3"   = "Jeg vet hvordan jeg kan tilpasse bruken av programmering til forskjellige undervisningsaktiviteter.",
"TPK4"   = "Jeg tenker kritisk gjennom hvordan jeg kan bruke programmering i undervisningen.",                                          
"TPK5"   = "Jeg vet hvordan jeg kan legge frem programmering på måter som motiverer for læring.",                                             
"PCK1"   = "Jeg vet hvordan jeg kan legge til rette for elevenes begrepslæring i naturfag.",                                        
"PCK2"   = "Jeg vet hvordan jeg kan støtte elevene i å utvikle kritisk tenkning og argumentasjonsferdigheter i naturfag.",
"PCK3"   = "Jeg vet hvordan jeg kan bruke utforskende arbeidsmåter i naturfag.",                                                           
"PCK4"   = "Jeg vet hvordan jeg kan bruke modellering som arbeidsmåte i naturfag.",                                    
"PCK5"   = "Jeg vet hvordan jeg kan vurdere elevenes måloppnåelse på ulike måter i naturfag.",                                            
"TPACK1" = "Jeg vet hvordan jeg kan motivere elevene for å bruke programmering til å lære naturfag, for eksempel ved å knytte det til elevenes interesser eller vise hvilken relevans det kan ha.",
"TPACK2" = "Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå mer av naturfaglige begreper og fenomener.",
"TPACK3" = "Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå mer av naturvitenskapelige tenkemåter og praksiser.",                                     
"TPACK4" = "Jeg vet hvordan jeg kan bruke programmering i naturfag til å lære elever hvordan teknologiske systemer fungerer.",
"TPACK5" = "Jeg føler meg klar til å bruke programmering til å undervise naturfag",
"XK1"    = "Jeg vet hvilke utfordringer elevene kan ha når de programmerer.",
"XK2"    = "Jeg har kunnskap om elevers ulike forutsetninger for å ta i bruk programmering.",                                          
"XK3"    = "Jeg vet hvordan programmering i naturfag bidrar til skolens samfunnsoppdrag.",                                               
"XK4"    = "Jeg kan være en ressursperson for kollegaene i skolen når det gjelder programmering i naturfag",
"XK5"    = "Jeg vet hvordan bruk av programmeringsteknologi kan påvirke læringssituasjonen i klasserommet.",
"XK6"    = "Jeg vet hvordan jeg kan lede en undervisningssituasjon i et klasserom der programmering er en sentral aktivitet.")

# select TPACK-questions
data_pilot_ren <- data_pilot_ren[,3:50]
```

#### pilot trelis_q

```{r pilot_trelis_q_cleaning}
# keep some columns
data_pilot_trelis_q <- rename(data_pilot_trelis_q,
                            "Trinn" =
                            "80. Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?")
data_pilot_trelis_q <- rename(data_pilot_trelis_q,
                            "Gender" =
                            "82. Er du:")
data_pilot_trelis_q <- rename(data_pilot_trelis_q,
                            "studiested" =
                            "79. Hvilket studiested studerer du ved?")
data_pilot_trelis_q <- rename(data_pilot_trelis_q,
                            "semester" =
                            "81. Hvilket studieår er du i?")

# change from year to semester
data_pilot_trelis_q$semester <- rep(7, 52)  # 4 år =  7. semester (høst)

# reorder some columns
data_pilot_trelis_q <- data_pilot_trelis_q %>% relocate(Trinn,      .before = "58. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_pilot_trelis_q <- data_pilot_trelis_q %>% relocate(Gender,     .before = "58. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_pilot_trelis_q <- data_pilot_trelis_q %>% relocate(studiested, .before = "Trinn")
data_pilot_trelis_q <- data_pilot_trelis_q %>% relocate(semester,   .before = "Trinn")

# remove blank rows / NA
# kilde: https://www.statology.org/remove-rows-in-r/
# select columns:
# kilde: https://www.statology.org/r-select-columns-by-index/
data_pilot_trelis_q        <- data_pilot_trelis_q[ , 54:77]

# select rows: (fjern to nederste rader med gjennomsnitt og standardavvik)
data_pilot_trelis_q        <- data_pilot_trelis_q[ 1:48, ]

# convert into numbers
data_pilot_trelis_q[,5:24] <- apply(data_pilot_trelis_q[,5:24], 2,
                    function(x) as.numeric(as.character(x)))
```

```{r pilot_trelis_q_rename}
# rename columns: (bruker dplyr)
# kilde: https://www.sharpsightlabs.com/blog/rename-columns-in-r/
data_pilot_trelis_q_ren <- rename(data_pilot_trelis_q, 
'CK123'  = '58. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.',
"CK6"    = "59. Jeg har kunnskap om hvordan forskere i naturvitenskap arbeider",
'CK5'    = '60. Jeg har kunnskaper om naturvitenskapelige tenkemåter og praksiser',
'PCK1'   = '61. Jeg vet hvordan jeg kan legge til rette for elevenes begrepslæring i naturfag',
'PCK2'   = '62. Jeg vet hvordan jeg kan støtte elevene i å utvikle kritisk tenkning og argumentasjonsferdigheter i naturfag',
'TK2'    = '63. Jeg kan lage algoritmer ved hjelp av penn og papir og flytdiagrammer.',
'TK5'    = '64. Jeg kan bruke variabler når jeg programmerer',
'TK6'    = '65. Jeg kan bruke vilkår (if, else), når jeg programmerer',
'TCK3'   = '66. Jeg kan utvikle modeller av naturfaglige fenomener ved hjelp av programmering og simulering',
'TCK4'   = '67. Jeg kan bruke programmering til å utforske naturfaglige fenomener',
'PK3'    = '68. Jeg kan støtte elevene sosialt i deres læring, f.eks deres nysgjerrighet, kreativitet og samarbeidsevne',
'PK1'    = '69. Jeg vet hvordan jeg kan støtte elevenes refleksjon over egen læring',
'PK6'    = '70. Jeg kan bruke vurdering underveis til å støtte elevene i deres læring',
'PCK4'   = '71. Jeg vet hvordan jeg kan bruke modellering som arbeidsmåte i naturfag',
'TPK1'   = '72. Jeg vet hvordan jeg kan bruke programmering på måter som beriker undervisningen',
'TPK4'   = '73. Jeg tenker kritisk gjennom hvordan jeg kan bruke programmering i undervisningen',
'TPK5'   = '74. Jeg vet hvordan jeg kan legge frem programmering på måter som motiverer for læring',
'TPACK2' = '75. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå mer av naturfaglige begreper og fenomener',
'TPACK3' = '76. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå naturvitenskapelige praksiser og tenkemåter.',
'TPACK4' = '77. Jeg vet hvordan jeg kan bruke programmering i naturfag til å lære elever hvordan teknologiske systemer fungerer.')
```

#### TRELIS-Q

```{r TRELIS_Q_cleaning}
# only keep relevant columns
data_trelis_q <- data_trelis_q[,51:74]

# keep some columns; covariates
# 68. Hvilket studiested studerer du ved?	
# 69. Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?	
# 70. Hvilket studieår er du i?	
# 71. Er du:

# likert-spørsmål: 48 - 66
# åpne spørsmål: 67

data_trelis_q <- rename(data_trelis_q,
                            "Trinn" =
                            "69. Går du på grunnskolelærerutdanning for trinn 1-7 eller trinn 5-10?")
data_trelis_q <- rename(data_trelis_q,
                            "Gender" =
                            "71. Er du:")
data_trelis_q <- rename(data_trelis_q,
                            "studiested" =
                            "68. Hvilket studiested studerer du ved?")
data_trelis_q <- rename(data_trelis_q,
                            "semester" =
                            "70. Hvilket studieår er du i?")

# change from year to semester
#data_trelis_q$semester <- rep(7, 52)  # 4 år =  7. semester (høst)

# reorder some columns
data_trelis_q <- data_trelis_q %>% relocate(Trinn, .before = "48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_trelis_q <- data_trelis_q %>% relocate(Gender, .before = "48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.")
data_trelis_q <- data_trelis_q %>% relocate(studiested, .before = "Trinn")
data_trelis_q <- data_trelis_q %>% relocate(semester, .before = "Trinn")
```

```{r TRELIS_Q_rename}
# rename columns: (bruker dplyr)
# kilde: https://www.sharpsightlabs.com/blog/rename-columns-in-r/
data_trelis_q_ren <- rename(data_trelis_q, 
'CK123'  = '48. Jeg forstår sentrale begreper i naturfag innen temaer som energi og materie, jorda og livet på jorda, kropp og helse osv.',
'CK4'    = "49. Jeg forstår teknologiske prinsipper og virkemåter som er relevante for naturfag",
'CK5'    = '50. Jeg har kunnskaper om naturvitenskapelige praksiser og tenkemåter',
'PCK2'   = '51. Jeg vet hvordan jeg kan støtte elevene i å utvikle kritisk tenkning og argumentasjonsferdigheter i naturfag',
'TK2'    = "52. Jeg kan sette opp en algoritme når jeg programmerer",
'TK1a'   = "53. Jeg kan bryte ned problemer i mindre deler når jeg programmerer",
'TK34'   = "54. Jeg har kunnskap om forskjellige programmeringsverktøy, f.eks. Makecode for Micro:bit, Scratch, Python, og lignende",
'TK1b'   = "55. Jeg kan oppdage og rette feil, når jeg programmerer.",
'TK567'  = "56. Jeg vet hvordan jeg lager kode som inneholder f.eks. variabler, vilkår (if, else) og løkker (for, while)",
'TCK1'   = "58. Jeg kan bruke programmering til å utvikle enkle teknologiske systemer som består av deler som virker sammen.",
'TCK4'   = '57. Jeg kan bruke programmering til å utforske naturfaglige fenomener',
'PK3'    = '59. Jeg kan støtte elevene sosialt i deres læring i ulike fag, f.eks deres nysgjerrighet, kreativitet og samarbeidsevne',
'PK1'    = '60. Jeg vet hvordan jeg kan støtte elevenes refleksjon over egen læring i ulike fag',
'PCK5'   = '61. Jeg vet hvordan jeg kan vurdere elevenes læring på ulike måter i naturfag',
'TPK1'   = '62. Jeg vet hvordan jeg kan bruke programmering på måter som beriker undervisningen i ulike fag',
'TPK4'   = '63. Jeg tenker kritisk igjennom hvordan jeg kan bruke programmering i undervisningen i ulike fag',
'TPACK2' = '64. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå naturfaglige begreper og fenomener',
'TPACK3' = '65. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå naturvitenskapelige praksiser og tenkemåter.',
'TPACK4' = '66. Jeg vet hvordan jeg kan bruke programmering i naturfag på måter som hjelper elevene å forstå hvordan teknologiske systemer fungerer')

# change "5 Stemmer veldig godt" and "1 Stemmer veldig dårlig" to 5 and 1
data_trelis_q_ren[data_trelis_q_ren == '1 Stemmer veldig dårlig'] <- "1"
data_trelis_q_ren[data_trelis_q_ren == '5 Stemmer veldig godt']   <- "5"

# hva gjør jeg med 9 / VET IKKE? Gjør om til NA?
# gjør om til NA; OBS! Ikke gjør disse NA om til tall med impute, pmm senere
data_trelis_q_ren[data_trelis_q_ren == 'VET IKKE'] <- NA # "9"

# convert into numbers
data_trelis_q_ren[,5:23] <-  apply(data_trelis_q_ren[,5:23], 2,
                    function(x) as.numeric(as.character(x)))
```

```{r rename_dataset}
data_TRELIS_Q <- data_trelis_q_ren
```

#### merge dataframes

```{r merge_data_pilot_emne2}
# begin with text-values: spring 2022
data_prepost_emne2_ren <- bind_rows(data_pre_emne2_ren,
                                    data_post_emne2_ren)
data_pilot_emne2_ren   <- bind_rows(data_prepost_emne2_ren, data_pilot_ren)
```

```{r convert_likert_to_numbers}
# data_list (enig = 1, osv.)
data_pilot_emne2_ren[data_pilot_emne2_ren == 'Veldig uenig'] <- "1"
data_pilot_emne2_ren[data_pilot_emne2_ren == 'Veldig enig']  <- "5"
data_pilot_emne2_ren[data_pilot_emne2_ren == 'Hverken enig eller uenig'] <- "3"
data_pilot_emne2_ren[data_pilot_emne2_ren == 'Uenig']        <- "2"
data_pilot_emne2_ren[data_pilot_emne2_ren == 'Enig']         <- "4"

# turn values into integer from character
# kilde: https://statisticsglobe.com/convert-data-frame-column-to-numeric-in-r
data_pilot_emne2_ren[,8:ncol(data_pilot_emne2_ren)] <- apply(
                    data_pilot_emne2_ren[,8:ncol(data_pilot_emne2_ren)], 2,
                    function(x) as.numeric(as.character(x)))
```

```{r merge_all_datasets}
data_TPACK_pilot <- bind_rows(data_pilot_emne2_ren, data_pilot_trelis_q_ren)
```

```{r identify_dataset_in_dataframe}
datasett <- c(replicate(21, "pre"),
              replicate(20, "post"),
              replicate(16, "pilot"),
              replicate(48, "pilot_trelis_q"))

data_TPACK_pilot <- cbind(datasett, data_TPACK_pilot)
```

### Save reduced datasets

Size of dataset

* emne2_pre:         `r dim(data_pre_emne2_ren)`
* emne2_post:        `r dim(data_post_emne2_ren)`
* pilot:             `r dim(data_pilot_ren)`
* pilot_trelis_q:    `r dim(data_pilot_trelis_q_ren)`

```{r save_data_pilot}
save(data_TPACK_pilot, file="../data/processed_data/tpack-pilot_2022.Rdata")
```

```{r save_data_TRELIS_Q}
save(data_TRELIS_Q, 
     file="../data/processed_data/tpack-trelis_q_paper1_2023.Rdata")
```

In the following we will only consider the pre-datasett, so we remove the post-data, which is to dissimilar from the pilot data.

```{r select_data_for_screening}
# emne2_anon (uten post)
data_TPACK_pilot_minuspost <- data_TPACK_pilot[
  data_TPACK_pilot$datasett != "post" & 
  data_TPACK_pilot$datasett != "pilot_trelis_q",]
```

## Step 5: Item reduction

The aim of this step is to reduce the number of items to the lowest necessary by removing redundant items based on individual item tests. Since our measure is a self-report questionnaire, the relevant tests are based on correlations (step 5.2 and 5.3) and consideration of missing data (step 5.5). Step 5.1 and 5.4 are omitted as they concern correct or wrong answers to tests, which is not relevant for a self-report measure. 

Factor analysis is based on linear analysis (i.e., ordinary least squares-regression (OLS)). Assumptions underlying OLS-regression are according to @christophersen_introduksjon_2018 that the residuals have both an average value of 0, constant variance (i.e,. homoscedasticity) and independence (i.e., no autocorrelation). In addition, the dependent variables should depend linearly on the independent variables, which should have no multicollinearity (i.e., meaning that no residuals(?) of independent variable should be strongly correlated with any of the other independent variables). 
In addition, according to @flora_old_2012, it is important to decide whether to treat the data as ordinal or interval, as this has consequences for how the items are screened. Treating the data as interval, requires checking of missing data, linearity (checking for outliers and collinearity, i.e., very strong correlation between variables), and normally distributed residuals, checks which are not necessary to do if the data are treated as ordinal. In addition, checks suggested by @izquierdo_exploratory_2014 were done, such as check of eigenvalues, item-test correlation and reliabilities (i.e., Cronbach's alpha).

* Step 5a: check residuals (normality, autocorrelation)
* Step 5b: check correlations (collinearity, multicollinearity)
* Step 5c: check outliers (skew, kurtosis, range)
* Step 5d: check missing (pattern: MCAR, MAR, NMAR)
* Step 5e: check eigenvalues, item-test correlation, reliability [@izquierdo_exploratory_2014]

A list of items is compiled for easier retrieval.

```{r}
TK_pos <- c("TK1","TK2","TK3","TK4","TK5","TK6","TK7","TK8")
PK_pos <- c("PK1","PK2","PK3","PK4","PK5","PK6")
CK_pos <- c("CK1","CK2","CK3","CK4","CK5","CK123","CK6")
PCK_pos <- c("PCK1","PCK2","PCK3","PCK4","PCK5")
TCK_pos <- c("TCK1","TCK2","TCK3","TCK4")
TPK_pos <- c("TPK1","TPK2","TPK3","TPK4","TPK5")
TPACK_pos <- c("TPACK1","TPACK2","TPACK3","TPACK4","TPACK5")

#TPACK_complete <- c(TK_pos, PCK_full_pos, TPACK_full_pos) # minus XK

TPACK_list <- list(TK=TK_pos,
                   CK=CK_pos,
                   PK=PK_pos,
                   PCK=PCK_pos,
                   TCK=TCK_pos,
                   TPK=TPK_pos,
                   TPACK=TPACK_pos)

# CK6 and CK123 is only used for the TRELIS-Q dataset, not the pilot dataset
TPACK_list$CK <- TPACK_list$CK[!TPACK_list$CK %in% c("CK6","CK123")]
```

### Ordinal or interval data?

When we have as few as five answer alternatives (i.e., 5-pt Likert scale), there are weighty arguments for considering the data as ordinal [@flora_old_2012; @izquierdo_exploratory_2014; @watkins_exploratory_2018]. Five answer alternatives do however begin to imitate an interval scale (i.e., a continous scale). Thus, researchers have also argued for considering 5-pt scales as being continuous [@christophersen_introduksjon_2018; @norman_likert_2010]. In order to use the full arsenal of parametric methods (i.e., the properties of the sample are decided by a few parameters), such as maximum likelihood (ML), we decided to consider the data as interval. To support this choice further, we also presented the five alternatives as points on a linear scale in our questionnaire to help the respondents visualise the alternatives as being on an interval scale. 

### Linearity?

Here I do checks for linearity, collinearity and multicollinearity.

Through an iterative process, the following items were identified as contributing to high collinearity (r>0.9). They were therefore excluded from the dataset.

```{r remove_collinear_items}
data_TPACK_pilot_minuspost <- data_TPACK_pilot_minuspost %>%
    # 25.5.2023: velg bort items som ikke er i TRELIS-Q
    select(-c("TK8","PK2","PK4","PK5","PK6","PCK1","PCK3","PCK4","TCK2","TCK3",
              "TPK2","TPK3","TPK5","TPACK1","TPACK5",
              "TPACK3", # colinear in trelis-q; "TK1","TPK1",
              "TK6","TK4", "PK1", "PK3"))
```

```{r linear_scatterplots}
# scatterplot som korrigerer for overlap mellom datapunkter
teller <- 0                          # hvor mange plot lager jeg?
#datasett_index <- 1
#start <- 1                          # siste item = datasett

end <- ncol(data_TPACK_pilot_minuspost)
i <- 1                               # start posisjon
for (var1 in names(TPACK_list)) {           # TPACK-element
  items <- colnames(data_TPACK_pilot_minuspost)[colnames(data_TPACK_pilot_minuspost) %in% TPACK_list[[var1]]]
  ifelse (length(items)>1, 
    y <- rowMeans(data_TPACK_pilot_minuspost[, items]), # y-variabel
    y <- data_TPACK_pilot_minuspost[, items])           # y består av bare ett item
  i <- i + 1                         # for å unngå duplikater
  for (var2 in items) {               # x-variabel
    # scatterplot
    # kilde: https://ggplot2-book.org/statistical-summaries.html
    # kilde: https://stackoverflow.com/questions/32004292/r-ggplot-for-loop-aes-variable
    x <- data_TPACK_pilot_minuspost[,var2]
    xy <- data.frame(t(rbind(y,x)))
    colnames(xy) <- c(var1,var2)
      
    # check for collinearity, r>0.90
    r <- cor.test(x,y)
      
    # 0.4 er moderat korrelasjon ift Christophersen (2018) kap. 3
    if (abs(r$estimate)>0.4) { # only plot scatterplots which may be linear?
      xy_plot <- ggplot(xy, aes_string(var2,var1)) +
        geom_point() +                            # shape=1,alpha=1/5
        geom_jitter() +
        ggtitle(paste("scatterplot", data_TPACK_pilot_minuspost$datasett))

      print(xy_plot)
    teller <- teller + 1   # count number of scatterplots
    }
  }
}
print(teller) # antall plot
```

```{r linear_scatterplots_aggregated}
teller <- 0                          # hvor mange plot lager jeg?
#datasett_index <- 1
#start <- 1                          # siste item = datasett

end <- ncol(data_TPACK_pilot_minuspost)
i <- 1                               # start posisjon
for (var1 in names(TPACK_list)) {           # TPACK-element
  items <- colnames(data_TPACK_pilot_minuspost)[colnames(data_TPACK_pilot_minuspost) %in% TPACK_list[[var1]]]
    
  if (length(items) == 0) {next} # skip empty items
    
  ifelse (length(items)>1,  # calculate average value
    y <- rowMeans(data_TPACK_pilot_minuspost[, items]), # y-variabel
    y <- data_TPACK_pilot_minuspost[, items])

  x <- data_TPACK_pilot_minuspost[, items]
    
  xy <- data.frame(y,x)
  colnames(xy) <- c(var1,items)
    
  # pivot_longer
  # Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0.
  # ℹ Please use `all_of()` or `any_of()` instead.
  xy_long <- pivot_longer(xy,!c(all_of(var1)), names_to="items",values_to = "likert")
    
  #Warning: `aes_string()` was deprecated in ggplot2 3.0.0.
  #ℹ Please use tidy evaluation idioms with `aes()`.
  #ℹ See also `vignette("ggplot2-in-packages")` for more information.

  xy_plot <- ggplot(xy_long, aes_string("likert",var1)) +
    geom_point() +                            # shape=1,alpha=1/5
    geom_jitter() +
    ggtitle(paste("scatterplot", data_TPACK_pilot_minuspost$datasett))

  print(xy_plot)
  teller <- teller + 1   # count number of scatterplots
}

print(teller) # antall plot
```

```{r check_collinearity}

### HELP FUNCTIONS

lag_eigenvalue_tabell <- function(ev_list) {
  no_ev <- length(ev_list) # antall eigenvalues
  kum_var <- 0
  
  # gjør om til tabell
  ev_tabell <- data.frame(matrix(ncol=4,nrow=0))
  for (i in 1:no_ev) {
    ev <- ev_list[i]
    kum_var <- kum_var + ev/no_ev
    faktor <- cbind(as.integer(i), ev, ev/no_ev, kum_var)
    #print(faktor)
    ev_tabell <- rbind(ev_tabell, faktor)
  }
  
  colnames(ev_tabell) <- c("Factor","Eigenvalue","Variance","Cummulativ variance")
  
  pander(format(ev_tabell,digits=2))
}


collinear <- function (dataset) {
  ###
  # Christophersen (2018): r > 0.9?
  ###
  
  teller <- 0                          # hvor mange sjekker gjør jeg?
  start <- 1                           
  end <- ncol(dataset)
  i <- 1                               # start posisjon
  for (var1 in colnames(dataset[start:(end-2)])) {
    i <- i + 1                         # for å unngå duplikater
    for (var2 in colnames(dataset[i:(end-1)])) {
      # check for collinearity, r>0.90
      r <- cor.test(dataset[,var1], dataset[,var2])
      
      if (abs(r$estimate)>0.9) { 
        print("collinearity: r > 0.90")
        print(c(dataset, var1 ,var2, r$estimate))   # marker verdier større enn 0.90
       
        teller <- teller + 1   # count number of scatterplots
      }
    }
  }
  
  if (teller == 0) {
    print("Ingen kolinearitet oppdaget") # antall plot
  }

  ###
  # Flora et al. (2012): eigenvalues <= 0? condition index < 30?
  ###
  ev <- eigen(cor(dataset,use="pairwise.complete.obs"), only.values=TRUE)
  ev_table <- lag_eigenvalue_tabell (ev$values)
  #ev
  # beregn condition index: ci < 30
  ci <- ev$values[1]**2 - ev$values[length(ev$values)]**2 
  print(c("Condition index(<30?):", ci))
  return(ev_table)
}

#datasett <- data_list[[1]]
# eigenvalue_table
ev_table <- collinear(data_TPACK_pilot_minuspost[,colnames(data_TPACK_pilot_minuspost) %in% unlist(TPACK_list)])
ev_table
```

```{r check_multicollinearity}
# multiple regression model

# I browse through the items, and remove the current item by subtracting it at the end of the formula
mc <- NULL      # list of items with multicollinearity
    
# kilde: https://www.codingprof.com/3-ways-to-test-for-multicollinearity-in-r-examples/
corrplot(cor(data_TPACK_pilot_minuspost[,colnames(data_TPACK_pilot_minuspost) %in% unlist(TPACK_list)]), method = "number", number.cex=0.3) # r bør være under 0.85

# forenkle navn på dataset for prettyprint
df <- data_TPACK_pilot_minuspost

#items <- unlist(TPACK_list)
items <- colnames(df[,colnames(df) %in% unlist(TPACK_list)]) # ikke ha med subset-kolonnen  

# lag tekststreng for uavhengige variable
#antall_tpack <- length(grep("TPACK",items))
independent_var <- paste("'] ~ df [,'", items[1], sep="") #TK1"
for (item in items[2:(length(items))]) { #-antall_tpack)]) { # omit TPACK
  independent_var <- paste(independent_var, "'] + df [,'", item, sep="")
}
independent_var <- paste(independent_var, "'] - df  [,'", sep="")
      
for (item in items) {
  model <- lm( as.formula(
  paste( "df [,'", item, independent_var, item, "']", sep="")))
     
  print("############################")
  print("######## NEW ITEM ##########")
  print("############################")
        
  print(item)

  # check for multicollinearity: R > 0.9
  print("Any R>0.9?")
  mc_items <- model$coefficients[abs(model$coefficients)>0.9]
  if (length(mc_items) > 0) {
    print(c("multicollinearitet R > 0.9?", mc_items))
    print(summary(model))
    mc <- c(mc, item)
  }

  #if (vif == 1) {
  # kilde: https://www.statology.org/multicollinearity-in-r/
  print("car::vif")
  print(vif(model))

  print("olsrr::vif")
  # kilde: https://www.codingprof.com/3-ways-to-test-for-multicollinearity-in-r-examples/
  print("tolerance bør være over 0.1 og VIF under 10.")
  print(ols_vif_tol(model)) # tolerance bør være over 0.1 og VIF under 10.
  #print("CI bør både være under 10 og varians lav")
  #print(ols_eigen_cindex(model)) # CI bør både være under 10 og varians lav
}

# print items with multicollinearity
print(mc)
```

No multicollinearity. The items added to mc are due to the intercepts, not the slopes. 

### Outliers?

Outliers may impact calculations of standard deviations. Flora et al. (2012) and Watkins (2018) recommend, however, not to remove outliers. Christophersen (2018) recommends to compare calculations with and without outliers to determine their significance. 

```{r}
### HELP FUNCTION
# describe data (mean, sd, skew, curtosis)
# requires library(moments) for skew
describe_data <- function (datalist, QUIET=1) {

  im  <- mean(datalist, na.rm=TRUE)
  isd <- sd(datalist, na.rm=TRUE)
  isk <- psych::skew(datalist, na.rm=TRUE) # from psych
  ik  <- kurtosi(datalist, na.rm=TRUE) # from psych
  mis <- sum(is.na(datalist)) # missing
  ir  <- max(datalist, na.rm=TRUE) - min(datalist, na.rm=TRUE) # range
  
  # source: https://stackoverflow.com/questions/34351598/getting-name-of-variable-in-r
  if (QUIET != 1) {
    print(sprintf("%7s = %s",   "Item",    deparse(substitute(datalist))))
    print(sprintf("%7s = %.3f", "mean",    im))
    print(sprintf("%7s = %.3f", "std.dev", isd))
    print(sprintf("%7s = %.3f", "skew",    isk))
    print(sprintf("%7s = %.3f", "kurt",    ik))
    print(sprintf("%7s = %.3f", "range",   ir))
    print(sprintf("%7s = %i",   "missing", mis))

    if (isk > 2 | ik > 7) {
      print("                            Skew or curtosis TOO LARGE.")
    }
  }
  
  # outliers
  lowerq = quantile(datalist, na.rm=TRUE)[2]
  upperq = quantile(datalist, na.rm=TRUE)[4]
  iqr    = upperq - lowerq               #Or use IQR(df)
  # gang med 3 for extreme outliers, 1.5 for mild outliers
  
  mild.threshold.upper = (iqr * 3) + upperq
  mild.threshold.lower = lowerq - (iqr * 3)
  
  # print outliers
  # kilde: https://stackoverflow.com/questions/19353116/how-do-i-print-values-in-a-list-that-are-greater-than-a-certain-number-along-wit#19353192
  outliers_upper <- which(datalist>mild.threshold.upper)
  outliersu      <- datalist[outliers_upper]
  outliers_lower <- which(datalist<mild.threshold.lower)
  outliersl      <- datalist[outliers_lower]
  
  if (length(outliersu) > 0 | length(outliersl) > 0) {
    print("outliers upper =")
    print(outliersu)
    print("outliers lower =")
    print(outliersl)
  }
  
  #hist (datalist, main=i) # histogram
  #readline(prompt = "Press enter")
  
  return(c("mean"=round(im,3), "skew"=round(isk,3), "kurtosi"=round(ik,3)))
           #round(outliersu,3), round(outliersl,3)))
}


# skip first column which is list of subsets
#datasett_index <- 1
#for (datasett in names(data_list)) {
  for (i in colnames(data_TPACK_pilot_minuspost)[colnames(data_TPACK_pilot_minuspost) %in% unlist(TPACK_list)]) {
    print(paste(i))
    describe_data(data_TPACK_pilot_minuspost[,i])
  }
#  datasett_index <- datasett_index + 1
#}

print(describe(data_TPACK_pilot_minuspost)) # independent variables, x
#print(describe(scoreItems(TPACK_list,data_TPACK_pilot_minuspost)$scores)) # dependent variables
```

### Normal distribution of residuals?

Statistical tests assume the residuals are normally distributed. Common criteria are that skewness should be below 2 or 3, and that curtosis (i.e., flatness, which is related to outliers) should be below 7 or 10 (Flora et al., 2012; Christophersen, 2018). 

y = ax + b + restledd

Residuals should have an average value of 0, equal variance (homoscedasticity) and no interdependence (no autocorrelation) (Christophersen, 2018, kap. 7).

```{r residuals_singleitems}
check_residuals <- function(dataset, items) {
  
  table_residuals <- NULL
  
  teller <- 0                          # hvor mange kombinasjoner sjekker jeg?
  i      <- 1                          # start posisjon
  end    <- length(items)
  for (var1 in items[1:(end-1)]) {
    ifelse (length(items)>1, 
      y  <- rowMeans(dataset[, items]), # y-variabel
      y  <- dataset[, items])           # y består av bare ett item
    
    i    <- i + 1                      # for å unngå duplikater
    for (var2 in items[i:end]) {       # x-variabel
      x  <- dataset[,var2]
      xy <- data.frame(t(rbind(y,x)))
      colnames(xy) <- c(var1,var2)
      
      model <- lm( as.formula(
      paste( "xy [,'", var1, "'] ~ xy [,'", var2, "']", sep="")))
 
      print(c(var1, "=", var2))
        
      # check for outliers in residuals
      descriptive <- (describe_data(model$residuals)) # returns ("mean"=im, "skew"=isk, "kurtosi"=ik, outliersu, outliersl)
        
      # grense for betydningsfulle outliers / leverage; s. 78 i Christophersen, 2018
      k          <- length(items) # antall uavhengige variables
      n          <- nrow(xy)
      ifelse (k<10, 
        leverage <- 3*(k+1)/n,
        leverage <- 2*(k+1)/n
      )
      #print(c("betydningsfull grense:", leverage))
        
      # check for normalfordeling
      # 1: normalfordeling av residuals?
      hist(residuals(model), col = "steelblue")
      # 2: jevn fordeling av varians, homoskedastisitet
      print(plot(fitted(model), residuals(model)))
      print(abline(h = 0, lty = 2))
         
      teller <- teller + 1   # count number of scatterplots

      # check for autocorrelation
      dw     <- durbinWatsonTest(model)
      print(dw)
      
      table_residuals <- rbind(table_residuals, c("var1"=var1, "var2"=var2, 
                                                  descriptive, 
                                                  "dw=2"=round(dw$dw,2)))
    } 
  }
  print(teller) # antall plot
  
  # gjør om til tabell
  table_residuals         <- data.frame(table_residuals)
  
  # gjør om til tall
  table_residuals$mean    <- as.numeric(table_residuals$mean)
  table_residuals$skew    <- as.numeric(table_residuals$skew)
  table_residuals$kurtosi <- as.numeric(table_residuals$kurtosi)
  table_residuals$'dw.2'  <- as.numeric(table_residuals$'dw.2')

  return (table_residuals)
}


items     <- colnames(data_TPACK_pilot_minuspost)[colnames(data_TPACK_pilot_minuspost) %in% unlist(TPACK_list)]
table_res <- check_residuals(data_TPACK_pilot_minuspost, items)

# print items with large skew og kurtosi or autocollinearity
pander(table_res[abs(table_res$skew) > 1. | abs(table_res$kurtosi) > 3. | table_res$dw.2 > 2.5 | table_res$dw.2 < 1.5,])
```

Are there correlating residuals?  
Autocorrelation: Durbin-Watsons d = 2*(1-r)  

If d = 2, then OK  
If d < 1 eller d > 3, then not OK

If autocorrelation, use robust SE

Autocorrelation can be due to structured data. Then use multilevel-analysis. 

```{r distribution_residuals_aggregated}
teller         <- 0                             # hvor mange plot lager jeg?
datasett_index <- 1
#for (dataset in names(data_list)) {
#  datasett <- data_list[[dataset]]      # access data object
  for (var1 in names(TPACK_list)) {     # TPACK-element
    items      <- colnames(data_TPACK_pilot_minuspost)[colnames(data_TPACK_pilot_minuspost) %in% TPACK_list[[var1]]]
    ifelse (length(items)>1,            # ikke gjør analyse hvis bare ett item
      y        <- rowMeans(data_TPACK_pilot_minuspost[, items]), # y-variabel
      y        <- 0)

   print(c(var1, "=", items))
   
   if (!length(y)==1) {                # sjekk for at vi har flere enn et item
    
      x        <- data_TPACK_pilot_minuspost[, items]
    
      xy       <- data.frame(y,x)
      colnames(xy) <- c(var1,items)
    
      # lag tekststreng til formel y= x1 + x2 + osv.
      independent_var <- paste("'] ~ xy [,'", items[1], sep="") #TK1"
      for (item in items[2:(length(items))]) { 
        independent_var <- paste(independent_var, "'] + xy [,'", item, sep="")
      }
      independent_var <- paste(independent_var, "'] - xy  [,'", sep="")
      
      #for (item in items) {
        model <- lm( as.formula(
        paste( "xy [,'", item, independent_var, item, "']", sep="")))

        # check for outliers in residuals
        print(describe_data(model$residuals))
        
        # grense for betydningsfulle outliers / leverage; s. 78 i Christophersen, 2018
        k <- length(items) # antall uavhengige variables
        n <- nrow(xy)
        ifelse (k<10, 
                leverage <- 3*(k+1)/n,
                leverage <- 2*(k+1)/n
                )
         print(c("betydningsfull grense:", leverage))
        
        # check for normalfordeling
        # 1: normalfordeling av residuals?
        print(hist(residuals(model), col = "steelblue"))
        # 2: jevn fordeling av varians, homoskedastisitet
        print(plot(fitted(model), residuals(model)))
        print(abline(h = 0, lty = 2))
         
        teller <- teller + 1   # count number of scatterplots
      #}
    }
  }
  #datasett_index <- datasett_index + 1
#} 
print(teller) # antall plot
    
```

### Missing?

Missing data reduces the size of the dataset used for analysis, which leads to lower power (i.e., larger chances for Type II-error, that is, not detecting significant effects, obtaining false negatives). There are different advice for how to handle missing data, depending on whether they are missing at random (MAR), completely at random (MCAR) or not at random (NMAR) [@rubin_inference_1975; @schafer_missing_2002]. Data that are missing at random are correlated with the questionnaire (i.e., a question may be missing from a specific version of a questionnaire, which is in a sense random). Data that are missing completely at random, do however not correlate with anything obvious. They are in a sense, seemingly truly random, with no clear rationale for their missing other than circumstance. Data missing not at random are questions that correlate with the question itself (i.e., several respondents may avoid a specific question, i.e., about gender, there seems to be a rationale, that is not a random cause, for data missing for this specific item). 

Ways to handle missing data is predictive mean matching when less than 10 % are missing, otherwise ML-methods [@weston_brief_2006; @flora_old_2012; @watkins_exploratory_2018; @mcneish_challenging_2017; @gallagher_introduction_2013]. 

```{r}
# ref: https://gabriellajg.github.io/EPSY-579-R-Cookbook-for-SEM/lavaan-lab-12-sem-for-missing-data.html
md.pattern(data_TPACK_pilot_minuspost)
```

n = 37  
9 are missing andre_fag  
16 are missing subject and gender  

## Step 6: Factor extraction (i.e., EFA)

# Stage 3 

From stage 3 there are three steps which will be discussed: step 7 (tests of dimensionality, i.e., CFA), step 8 (tests of reliability) and step 9 (tests of validity). 

## Step 7: Tests of dimensionality (i.e., CFA)

## Step 8: Tests of reliability

## Step 9: Tests of validity


# Discussion and conclusion



# References

<!-- citation(package) -->

<div id="refs"></div>

<!-- source: https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html 

# (APPENDIX) Appendix {-} -->

# Session info
<!-- # ref.: https://intro2r.com/proj_doc.html -->
<!-- #sessionInfo() -->

```{r}
xfun::session_info()
```
